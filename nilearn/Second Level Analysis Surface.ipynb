{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8420cab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pixdim[1,2,3] should be non-zero; setting 0 dims to 1\n"
     ]
    }
   ],
   "source": [
    "#Import packages\n",
    "import os\n",
    "import glob\n",
    "import json\n",
    "import pickle\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "#from tqdm import tqdm\n",
    "\n",
    "import nilearn\n",
    "import nibabel as nib\n",
    "from nibabel import load\n",
    "from nibabel.gifti import GiftiDataArray, GiftiImage\n",
    "\n",
    "from nilearn import image as nimg\n",
    "from nilearn import plotting as nplot\n",
    "from nilearn.glm.first_level import FirstLevelModel, make_first_level_design_matrix, run_glm\n",
    "from nilearn.glm.second_level import make_second_level_design_matrix, SecondLevelModel\n",
    "from nilearn.glm import fdr_threshold,threshold_stats_img\n",
    "from nilearn.glm.contrasts import compute_contrast, _compute_fixed_effects_params\n",
    "from bids.layout import BIDSLayout, parse_file_entities\n",
    "\n",
    "# import cortex\n",
    "# from cortex import fmriprep\n",
    "\n",
    "from nipype.interfaces.workbench.base import WBCommand\n",
    "from nipype.algorithms import modelgen\n",
    "from nipype.interfaces.base import Bunch\n",
    "\n",
    "import scipy.stats as stats\n",
    "\n",
    "import hcp_utils as hcp\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "#my utilities package\n",
    "import utils\n",
    "\n",
    "#%matplotlib inline\n",
    "#! module load openmind/hcp-workbench/1.2.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9642cb93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5,\n",
       " 10,\n",
       " 10,\n",
       " [('sub-voice856_ses-1_task-emosent', 'contrast-speechvsil'),\n",
       "  ('sub-voice859_ses-1_task-emosent', 'contrast-speechvsil'),\n",
       "  ('sub-voice860_ses-1_task-emosent', 'contrast-speechvsil'),\n",
       "  ('sub-voice875_ses-1_task-emosent', 'contrast-speechvsil'),\n",
       "  ('sub-voice893_ses-1_task-emosent', 'contrast-speechvsil')])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#take all the first level files and parse out subject, session, and task name, remove repeats \n",
    "\n",
    "#first_level_root = f'../../derivatives/first_level_110123'\n",
    "\n",
    "#folder = 'first_level_percondition'\n",
    "#folder = 'first_level_emosent_ftest_112523'\n",
    "#folder = 'first_level_emosent_emospeech_112523'\n",
    "# folder = 'first_level_emosent_sadneutral_112713'\n",
    "# first_level_root = f'../../derivatives/{folder}/'\n",
    "folder = 'test'\n",
    "first_level_root = 'test/'\n",
    "#first_level_root = '../../derivatives/first_level_main_112223/'\n",
    "first_level_effects = glob.glob(f'{first_level_root}/*effect_size*.dscalar.nii')\n",
    "effect_variances = glob.glob(f'{first_level_root}/*effect_variance*.dscalar.nii')\n",
    "\n",
    "#load list of runs to exclude and format as a list of bids-compliant names\n",
    "# exclude_df = pd.read_table('../../derivatives/first_level_110123/no_wall_of_speech_exclude_110123 - Sheet1.tsv')\n",
    "\n",
    "# exclude = []\n",
    "# for i, r in exclude_df.iterrows():\n",
    "#     sub = r['sub']\n",
    "#     ses = r['ses']\n",
    "#     task = r.iloc[5]\n",
    "#     run = r['run']\n",
    "#     exclude.append(f'sub-voice{sub}_ses-{ses}_task-{task}_rec-unco_run-{run}')\n",
    "\n",
    "    \n",
    "    \n",
    "#remove runs from exclusion list\n",
    "effects_qc = [beta for beta in first_level_effects] \n",
    "#                       if beta.split(f'{folder}/')[1].split('_space')[0] not in exclude]\n",
    "variance_qc = [beta for beta in effect_variances]\n",
    "#                       if beta.split(f'{folder}/')[1].split('_space')[0] not in exclude]\n",
    "\n",
    "\n",
    "\n",
    "#get final list of sub/ses/tasks we want after fixed effects pooling\n",
    "#sub_ses_task_wdup = [sn.split(f'{folder}/')[1].split('_rec-unco')[0] for sn in effects_qc]\n",
    "sub_ses_task_wdup = [(sn.split(f'{folder}/')[1].split('_rec-unco')[0], sn.split('_den-91k_')[1].split('_effect_')[0]) \n",
    "                     for sn in effects_qc]\n",
    "sub_ses_task = []\n",
    "[sub_ses_task.append(x) for x in sub_ses_task_wdup if x not in sub_ses_task]\n",
    "\n",
    "#keep only the tasks we want\n",
    "#task_list = ['nwr','emosent']\n",
    "task_list = ['emosent']\n",
    "con = 'speechvsil'\n",
    "#con = 'happyvneutral'\n",
    "#task_list = ['pataka', 'emosent', 'vowel', 'nwr']\n",
    "sub_ses_task = [sst for task in task_list for sst in sub_ses_task  if task in sst[0]] \n",
    "sub_ses_task = [sst for sst in sub_ses_task  if con in sst[1]] \n",
    "\n",
    "len(sub_ses_task), len(effects_qc), len(variance_qc), sub_ses_task[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73fc8197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sub-voice856_ses-1_task-emosent_rec-unco_space-fsLR_den-91k_contrast-speechvsil_effect_size_fx.dscalar.nii\r\n",
      "sub-voice856_ses-1_task-emosent_rec-unco_space-fsLR_den-91k_contrast-speechvsil_effect_variance_fx.dscalar.nii\r\n",
      "sub-voice856_ses-1_task-emosent_rec-unco_space-fsLR_den-91k_contrast-speechvsil_stat_fx.dscalar.nii\r\n",
      "sub-voice859_ses-1_task-emosent_rec-unco_space-fsLR_den-91k_contrast-speechvsil_effect_size_fx.dscalar.nii\r\n",
      "sub-voice859_ses-1_task-emosent_rec-unco_space-fsLR_den-91k_contrast-speechvsil_effect_variance_fx.dscalar.nii\r\n",
      "sub-voice859_ses-1_task-emosent_rec-unco_space-fsLR_den-91k_contrast-speechvsil_stat_fx.dscalar.nii\r\n",
      "sub-voice860_ses-1_task-emosent_rec-unco_space-fsLR_den-91k_contrast-speechvsil_effect_size_fx.dscalar.nii\r\n",
      "sub-voice860_ses-1_task-emosent_rec-unco_space-fsLR_den-91k_contrast-speechvsil_effect_variance_fx.dscalar.nii\r\n",
      "sub-voice860_ses-1_task-emosent_rec-unco_space-fsLR_den-91k_contrast-speechvsil_stat_fx.dscalar.nii\r\n",
      "sub-voice875_ses-1_task-emosent_rec-unco_space-fsLR_den-91k_contrast-speechvsil_effect_size_fx.dscalar.nii\r\n",
      "sub-voice875_ses-1_task-emosent_rec-unco_space-fsLR_den-91k_contrast-speechvsil_effect_variance_fx.dscalar.nii\r\n",
      "sub-voice875_ses-1_task-emosent_rec-unco_space-fsLR_den-91k_contrast-speechvsil_stat_fx.dscalar.nii\r\n",
      "sub-voice893_ses-1_task-emosent_rec-unco_space-fsLR_den-91k_contrast-speechvsil_effect_size_fx.dscalar.nii\r\n",
      "sub-voice893_ses-1_task-emosent_rec-unco_space-fsLR_den-91k_contrast-speechvsil_effect_variance_fx.dscalar.nii\r\n",
      "sub-voice893_ses-1_task-emosent_rec-unco_space-fsLR_den-91k_contrast-speechvsil_stat_fx.dscalar.nii\r\n"
     ]
    }
   ],
   "source": [
    "#!rm test/second_level/*\n",
    "!ls test/second_level/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84d69f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#out_dir = '../../derivatives/second_level_main_112223'\n",
    "#out_dir = '../../derivatives/second_level_percondition_112123'\n",
    "#out_dir = '../../derivatives/second_level_emosent_ftest_112523'\n",
    "#out_dir = '../../derivatives/second_level_emosent_emospeech_112523'\n",
    "#out_dir = '../../derivatives/second_level_emosent_sadneutral_112713'\n",
    "out_dir = 'test/second_level'\n",
    "\n",
    "\n",
    "for info in sub_ses_task:\n",
    "    \n",
    "    #filter out sub, ses, task, and contrast we want\n",
    "    effect_size_list = [file for file in effects_qc if info[0] in file]\n",
    "    effect_size_list = [file for file in effect_size_list if info[1] in file]\n",
    "    \n",
    "    effect_var_list = [file for file in variance_qc if info[0] in file]\n",
    "    effect_var_list = [file for file in effect_var_list if info[1] in file]\n",
    "\n",
    "    if effect_size_list:\n",
    "\n",
    "        # no fixed effects if only 1 run for a subject, copy first level betas to second level folder\n",
    "        if len(effect_size_list) == 1:\n",
    "            shutil.copy(effect_size_list[0], os.path.join(out_dir, str(Path(effect_size_list[0]).relative_to(first_level_root))))\n",
    "            shutil.copy(effect_var_list[0], os.path.join(out_dir, str(Path(effect_var_list[0]).relative_to(first_level_root))))\n",
    "        \n",
    "        # pool multiple runs from one subject with fixed effects and save outputs\n",
    "        elif len(effect_size_list) > 1:                \n",
    "            fx_results = _compute_fixed_effects_params(\n",
    "                np.squeeze(\n",
    "                     [nib.load(fname).get_fdata(dtype='f4') for fname in effect_size_list]\n",
    "                 ),\n",
    "                 np.squeeze(\n",
    "                     [nib.load(fname).get_fdata(dtype='f4') for fname in effect_var_list]\n",
    "                 ),\n",
    "                 precision_weighted=False)\n",
    "            \n",
    "            #save the outputs\n",
    "            #note the order of fixed effects outputs: fx_results = [fixed_fx_contrast, fixed_fx_variance, fixed_fx_tstat]            \n",
    "            utils.save_cifti(fx_results[0], 'effect_size_fx', out_dir, info[0] + '_rec-unco', contrast=info[1].split('contrast-')[1])\n",
    "            utils.save_cifti(fx_results[1], 'effect_variance_fx', out_dir, info[0] + '_rec-unco',contrast=info[1].split('contrast-')[1])\n",
    "            utils.save_cifti(fx_results[2], 'stat_fx', out_dir, info[0] + '_rec-unco',contrast=info[1].split('contrast-')[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56e53c47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[memmap([[-12.714197, -25.39303 , 254.86409 , ...,  20.513195,  38.321392,\n",
       "           47.17918 ]], dtype=float32),\n",
       " memmap([[-35.603855 ,  19.969484 , 275.52957  , ...,  37.12193  ,\n",
       "           -2.1463413,   7.1514325]], dtype=float32)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[nib.load(fname).get_fdata(dtype='f4') for fname in effect_size_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7544c6dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 91282)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.squeeze(\n",
    "                     [nib.load(fname).get_fdata(dtype='f4') for fname in effect_size_list]\n",
    "                 ).shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
