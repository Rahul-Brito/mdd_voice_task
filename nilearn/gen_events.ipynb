{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as op\n",
    "from glob import iglob\n",
    "import re\n",
    "from csv import reader, writer\n",
    "import glob\n",
    "\n",
    "from bids import BIDSLayout\n",
    "from bids.layout import BIDSLayout, parse_file_entities\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1test = {}\n",
    "v1test_pop = {}\n",
    "for s,i in pop.items(): \n",
    "    if i:\n",
    "        #did any of the subjects with log in visit 2 had log in visit 1 (seems like no)\n",
    "        v1test[s] = sorted(glob.glob(f'{psychopy_root}/voice{s}/session001_visit001/behavioral/*{task}*.log')) \n",
    "    else:\n",
    "        #did all the subjects with no log in visit 2 have a log in visit 1\n",
    "        #v1test_pop[s] = os.listdir(f'{psychopy_root}/voice{s}/') #also see if there are other sessions (there aren't)\n",
    "        v1test_pop[s] = sorted(glob.glob(f'{psychopy_root}/voice{s}/session001_visit001/behavioral/*{task}*.log')) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#top level where all subject folders/psychopy log files are\n",
    "psychopy_root = '/nese/mit/group/sig/om_projects/voice/rawData'\n",
    "task = 'emosent'\n",
    "\n",
    "sub_list = [856, 859, 860, 867, 872, 873, 875, 877, 891, \n",
    "            893, 895, 896, 897, 898, 957, 962, 963, 967, \n",
    "            968, 969, 973, 976, 978, 979, 981]\n",
    "sub_list = [str(s) for s in sub_list]\n",
    "\n",
    "pop = {s: sorted(glob.glob(f'{psychopy_root}/voice{s}/session001_visit002/behavioral/*{task}*.log')) for s in sub_list}\n",
    "\n",
    "#sub_num = '856'\n",
    "\n",
    "#log file with full path sorted so they are sorted by timestamp value\n",
    "\n",
    "log_files = {}\n",
    "for s,i in pop.items(): \n",
    "    if i:\n",
    "        #already found ones from visit 2\n",
    "        log_files[s] = i \n",
    "    else:\n",
    "        #add logs from visit 1\n",
    "        log_files[s] = sorted(glob.glob(f'{psychopy_root}/voice{s}/session001_visit001/behavioral/*{task}*.log')) \n",
    "\n",
    "# sub_num = '980'\n",
    "# task = 'nwr'\n",
    "#log_files_full = sorted(glob.glob(f'{psychopy_root}/voice{sub_num}/session001_visit002/behavioral/*{task}*.log'))\n",
    "#log_files_full = sorted(glob.glob(f'{psychopy_root}/voice{sub_num}/session001_visit001/behavioral/*{task}*.log'))\n",
    "\n",
    "#list of names of each log file with base path stripped\n",
    "#log_files = sorted([lo.split('behavioral/')[1] for lo in log_files_full])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "scan_info = {}\n",
    "for sub_num in sub_list:\n",
    "    #load scans.tsv file for this subject and filter by task\n",
    "    sc = pd.read_table(f'../../sub-voice{sub_num}/ses-1/sub-voice{sub_num}_ses-1_scans.tsv')\n",
    "    scan_info[sub_num] = sc[sc.filename.str.contains(task)]#[['filename', 'acq_time']].reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_log_match = {}\n",
    "    \n",
    "#loop through each scan for this task and subject\n",
    "for sub_num, sc in scan_info.items():\n",
    "    ordered_logs = []\n",
    "    for i,scan in sc.iterrows():\n",
    "\n",
    "        #get acqusition time of a scan from scans.tsv file\n",
    "        s_time_format = '%Y-%m-%dT%H:%M:%S.%f'\n",
    "        s_time_obj = datetime.strptime(scan.acq_time, s_time_format)\n",
    "        s_time_obj = s_time_obj.replace(microsecond=0) #drop seconds and ms, just comparing by minutes\n",
    "\n",
    "        #loop through each log file and compare timestamps of log file to scan.tsv acqusition time\n",
    "        \n",
    "        for logf in log_files[sub_num]:\n",
    "\n",
    "            #remove base path\n",
    "            log = logf.split('behavioral/')[1]\n",
    "\n",
    "            #just extract timestamp from filename\n",
    "            log_time = log.split('_voice')[0]\n",
    "            log_time_format = '%Y%m%d%H%M%S'\n",
    "            log_time_obj = datetime.strptime(log_time, log_time_format)\n",
    "\n",
    "            #check if scan.tsv time and log file time are the same\n",
    "            # to determine if they are from the same run\n",
    "            # see if they are with 30 seconds\n",
    "            if -60 <= s_time_obj.timestamp()- log_time_obj.timestamp() <=60:\n",
    "                ordered_logs.append((logf, parse_file_entities(scan.filename)))\n",
    "    run_log_match[sub_num] = (ordered_logs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_s = '875'\n",
    "#867 scan1 is 212 from the \"wrong\"? one that it closest to scan 2, 213 from the \"right\" on that is scan1\n",
    "#seems wrong for a bunch of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('/nese/mit/group/sig/om_projects/voice/rawData/voice875/session001_visit002/behavioral/20150706115628_voice875_S001_T005_R001_emosent.log',\n",
       "  {'subject': 'voice875',\n",
       "   'session': '1',\n",
       "   'task': 'emosent',\n",
       "   'run': 1,\n",
       "   'suffix': 'bold',\n",
       "   'extension': '.nii.gz'}),\n",
       " ('/nese/mit/group/sig/om_projects/voice/rawData/voice875/session001_visit002/behavioral/20150706120056_voice875_S001_T005_R002_emosent.log',\n",
       "  {'subject': 'voice875',\n",
       "   'session': '1',\n",
       "   'task': 'emosent',\n",
       "   'run': 2,\n",
       "   'suffix': 'bold',\n",
       "   'extension': '.nii.gz'})]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_log_match[test_s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/nese/mit/group/sig/om_projects/voice/rawData/voice875/session001_visit002/behavioral/20150706115628_voice875_S001_T005_R001_emosent.log',\n",
       " '/nese/mit/group/sig/om_projects/voice/rawData/voice875/session001_visit002/behavioral/20150706120056_voice875_S001_T005_R002_emosent.log']"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_files[test_s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>acq_time</th>\n",
       "      <th>operator</th>\n",
       "      <th>randstr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>func/sub-voice875_ses-1_task-emosent_run-1_bol...</td>\n",
       "      <td>2015-07-06T11:57:20.057500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f239d838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>func/sub-voice875_ses-1_task-emosent_run-2_bol...</td>\n",
       "      <td>2015-07-06T12:01:11.667500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cfe7e4f7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             filename   \n",
       "15  func/sub-voice875_ses-1_task-emosent_run-1_bol...  \\\n",
       "16  func/sub-voice875_ses-1_task-emosent_run-2_bol...   \n",
       "\n",
       "                      acq_time  operator   randstr  \n",
       "15  2015-07-06T11:57:20.057500       NaN  f239d838  \n",
       "16  2015-07-06T12:01:11.667500       NaN  cfe7e4f7  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scan_info[test_s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2015-07-27T17:47:09.105000'"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = 10\n",
    "scan_info[test_s].acq_time.loc[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2015, 7, 27, 17, 47, 9)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_time_obj = datetime.strptime(scan_info[test_s].acq_time.loc[index], s_time_format)\n",
    "s_time_obj = s_time_obj.replace(microsecond=0) \n",
    "s_time_obj#.timestamp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2015, 7, 27, 17, 50, 41)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_time_obj = datetime.strptime('20150727175041', log_time_format)\n",
    "log_time_obj#.timestamp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-212.0"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_time_obj.timestamp()- log_time_obj.timestamp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-30 <= s_time_obj.timestamp()- log_time_obj.timestamp() <=30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>onset</th>\n",
       "      <th>duration</th>\n",
       "      <th>trial_type</th>\n",
       "      <th>sentence</th>\n",
       "      <th>speak_start</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.92</td>\n",
       "      <td>4.0</td>\n",
       "      <td>sad</td>\n",
       "      <td>I can't seem to do well on my exams</td>\n",
       "      <td>5.0525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.92</td>\n",
       "      <td>3.99</td>\n",
       "      <td>silent</td>\n",
       "      <td>n/a</td>\n",
       "      <td>9.0523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15.91</td>\n",
       "      <td>4.0</td>\n",
       "      <td>happy</td>\n",
       "      <td>What joke could be funnier than that?</td>\n",
       "      <td>17.0425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19.91</td>\n",
       "      <td>4.0</td>\n",
       "      <td>happy</td>\n",
       "      <td>That was a blast</td>\n",
       "      <td>21.0423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23.91</td>\n",
       "      <td>4.0</td>\n",
       "      <td>silent</td>\n",
       "      <td>n/a</td>\n",
       "      <td>25.0423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>27.91</td>\n",
       "      <td>3.99</td>\n",
       "      <td>sad</td>\n",
       "      <td>Please forgive me</td>\n",
       "      <td>29.0419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>31.90</td>\n",
       "      <td>4.0</td>\n",
       "      <td>happy</td>\n",
       "      <td>I highly recommend that professor</td>\n",
       "      <td>33.0318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>35.90</td>\n",
       "      <td>4.0</td>\n",
       "      <td>happy</td>\n",
       "      <td>Isn't that beautiful?</td>\n",
       "      <td>37.032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>39.90</td>\n",
       "      <td>4.0</td>\n",
       "      <td>sad</td>\n",
       "      <td>If only I could go back</td>\n",
       "      <td>41.032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>43.90</td>\n",
       "      <td>3.99</td>\n",
       "      <td>happy</td>\n",
       "      <td>He's always pleasant to be around</td>\n",
       "      <td>45.0319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>51.89</td>\n",
       "      <td>4.0</td>\n",
       "      <td>sad</td>\n",
       "      <td>If only I hadn't said those things</td>\n",
       "      <td>53.022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>55.89</td>\n",
       "      <td>4.0</td>\n",
       "      <td>silent</td>\n",
       "      <td>n/a</td>\n",
       "      <td>57.0221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>59.89</td>\n",
       "      <td>3.99</td>\n",
       "      <td>sad</td>\n",
       "      <td>My best friend moved away</td>\n",
       "      <td>61.0219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>63.88</td>\n",
       "      <td>4.0</td>\n",
       "      <td>sad</td>\n",
       "      <td>That movie made me cry</td>\n",
       "      <td>65.012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>67.88</td>\n",
       "      <td>4.0</td>\n",
       "      <td>sad</td>\n",
       "      <td>That newspaper article was depressing</td>\n",
       "      <td>69.012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>71.88</td>\n",
       "      <td>4.0</td>\n",
       "      <td>silent</td>\n",
       "      <td>n/a</td>\n",
       "      <td>73.0118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>75.88</td>\n",
       "      <td>4.0</td>\n",
       "      <td>sad</td>\n",
       "      <td>I wish I could please them</td>\n",
       "      <td>77.012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>83.87</td>\n",
       "      <td>4.0</td>\n",
       "      <td>silent</td>\n",
       "      <td>n/a</td>\n",
       "      <td>85.0021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>91.87</td>\n",
       "      <td>4.0</td>\n",
       "      <td>happy</td>\n",
       "      <td>I look forward to meeting you</td>\n",
       "      <td>93.0015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>95.87</td>\n",
       "      <td>3.99</td>\n",
       "      <td>silent</td>\n",
       "      <td>n/a</td>\n",
       "      <td>97.0028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>99.86</td>\n",
       "      <td>4.0</td>\n",
       "      <td>happy</td>\n",
       "      <td>The soup is delicious</td>\n",
       "      <td>100.9922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>103.86</td>\n",
       "      <td>4.0</td>\n",
       "      <td>happy</td>\n",
       "      <td>The mountains are supposed to be nice this tim...</td>\n",
       "      <td>104.992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>107.86</td>\n",
       "      <td>4.0</td>\n",
       "      <td>silent</td>\n",
       "      <td>n/a</td>\n",
       "      <td>108.9921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>115.86</td>\n",
       "      <td>3.99</td>\n",
       "      <td>sad</td>\n",
       "      <td>My brother is very sick</td>\n",
       "      <td>116.9922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>119.85</td>\n",
       "      <td>4.0</td>\n",
       "      <td>silent</td>\n",
       "      <td>n/a</td>\n",
       "      <td>120.982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>123.85</td>\n",
       "      <td>4.0</td>\n",
       "      <td>sad</td>\n",
       "      <td>I felt so helpless</td>\n",
       "      <td>124.9818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>127.85</td>\n",
       "      <td>4.0</td>\n",
       "      <td>sad</td>\n",
       "      <td>I didn't mean to hurt your feelings</td>\n",
       "      <td>128.9817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>131.85</td>\n",
       "      <td>3.99</td>\n",
       "      <td>happy</td>\n",
       "      <td>The atmosphere there is very nice</td>\n",
       "      <td>132.9816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>139.84</td>\n",
       "      <td>4.0</td>\n",
       "      <td>silent</td>\n",
       "      <td>n/a</td>\n",
       "      <td>140.9716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>143.84</td>\n",
       "      <td>4.0</td>\n",
       "      <td>happy</td>\n",
       "      <td>I can't wait to see you</td>\n",
       "      <td>144.9718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>147.84</td>\n",
       "      <td>3.99</td>\n",
       "      <td>sad</td>\n",
       "      <td>My dog died yesterday</td>\n",
       "      <td>148.9718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>155.83</td>\n",
       "      <td>4.0</td>\n",
       "      <td>silent</td>\n",
       "      <td>n/a</td>\n",
       "      <td>156.9616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>163.83</td>\n",
       "      <td>4.0</td>\n",
       "      <td>happy</td>\n",
       "      <td>I would definitely like another slice</td>\n",
       "      <td>164.9617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>171.82</td>\n",
       "      <td>4.0</td>\n",
       "      <td>silent</td>\n",
       "      <td>n/a</td>\n",
       "      <td>172.9518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>175.82</td>\n",
       "      <td>4.0</td>\n",
       "      <td>happy</td>\n",
       "      <td>Have you ever tasted anything better?</td>\n",
       "      <td>176.9516</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     onset duration trial_type   \n",
       "0     3.92      4.0        sad  \\\n",
       "1     7.92     3.99     silent   \n",
       "2    15.91      4.0      happy   \n",
       "3    19.91      4.0      happy   \n",
       "4    23.91      4.0     silent   \n",
       "5    27.91     3.99        sad   \n",
       "6    31.90      4.0      happy   \n",
       "7    35.90      4.0      happy   \n",
       "8    39.90      4.0        sad   \n",
       "9    43.90     3.99      happy   \n",
       "10   51.89      4.0        sad   \n",
       "11   55.89      4.0     silent   \n",
       "12   59.89     3.99        sad   \n",
       "13   63.88      4.0        sad   \n",
       "14   67.88      4.0        sad   \n",
       "15   71.88      4.0     silent   \n",
       "16   75.88      4.0        sad   \n",
       "17   83.87      4.0     silent   \n",
       "18   91.87      4.0      happy   \n",
       "19   95.87     3.99     silent   \n",
       "20   99.86      4.0      happy   \n",
       "21  103.86      4.0      happy   \n",
       "22  107.86      4.0     silent   \n",
       "23  115.86     3.99        sad   \n",
       "24  119.85      4.0     silent   \n",
       "25  123.85      4.0        sad   \n",
       "26  127.85      4.0        sad   \n",
       "27  131.85     3.99      happy   \n",
       "28  139.84      4.0     silent   \n",
       "29  143.84      4.0      happy   \n",
       "30  147.84     3.99        sad   \n",
       "31  155.83      4.0     silent   \n",
       "32  163.83      4.0      happy   \n",
       "33  171.82      4.0     silent   \n",
       "34  175.82      4.0      happy   \n",
       "\n",
       "                                             sentence speak_start  \n",
       "0                 I can't seem to do well on my exams      5.0525  \n",
       "1                                                 n/a      9.0523  \n",
       "2               What joke could be funnier than that?     17.0425  \n",
       "3                                    That was a blast     21.0423  \n",
       "4                                                 n/a     25.0423  \n",
       "5                                   Please forgive me     29.0419  \n",
       "6                   I highly recommend that professor     33.0318  \n",
       "7                               Isn't that beautiful?      37.032  \n",
       "8                             If only I could go back      41.032  \n",
       "9                   He's always pleasant to be around     45.0319  \n",
       "10                 If only I hadn't said those things      53.022  \n",
       "11                                                n/a     57.0221  \n",
       "12                          My best friend moved away     61.0219  \n",
       "13                             That movie made me cry      65.012  \n",
       "14              That newspaper article was depressing      69.012  \n",
       "15                                                n/a     73.0118  \n",
       "16                         I wish I could please them      77.012  \n",
       "17                                                n/a     85.0021  \n",
       "18                      I look forward to meeting you     93.0015  \n",
       "19                                                n/a     97.0028  \n",
       "20                              The soup is delicious    100.9922  \n",
       "21  The mountains are supposed to be nice this tim...     104.992  \n",
       "22                                                n/a    108.9921  \n",
       "23                            My brother is very sick    116.9922  \n",
       "24                                                n/a     120.982  \n",
       "25                                 I felt so helpless    124.9818  \n",
       "26                I didn't mean to hurt your feelings    128.9817  \n",
       "27                  The atmosphere there is very nice    132.9816  \n",
       "28                                                n/a    140.9716  \n",
       "29                            I can't wait to see you    144.9718  \n",
       "30                              My dog died yesterday    148.9718  \n",
       "31                                                n/a    156.9616  \n",
       "32              I would definitely like another slice    164.9617  \n",
       "33                                                n/a    172.9518  \n",
       "34              Have you ever tasted anything better?    176.9516  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pairs in run_log_match.values():\n",
    "    for match in pairs:\n",
    "        logf = match[0]\n",
    "        evf = match[1]\n",
    "\n",
    "        full_events = []\n",
    "        with open(logf, encoding='utf-8') as fp:\n",
    "            conds = []\n",
    "            onset_timestamp = []\n",
    "            onsets = []\n",
    "            sentences = []\n",
    "            speak_start_timestamp = []\n",
    "            # time when first volume is acquired\n",
    "            start = -1\n",
    "\n",
    "            for line in fp:\n",
    "                if 'polygon: autoDraw = True' in line:\n",
    "                    polygon = line #float(re.search(\"^\\d+.\\d+\", line).group(0))\n",
    "                    speak_start_timestamp.append(float(re.search(\"^\\d+.\\d+\", polygon).group(0)))\n",
    "\n",
    "                # we only care about new trials\n",
    "                if 'New trial' not in line:\n",
    "                    continue\n",
    "                try:\n",
    "                    # onset time\n",
    "                    onset = float(re.search(\"^\\d+.\\d+\", line).group(0))\n",
    "                    # condition and sentences are coded as blank\n",
    "                    cond = re.search(\"(?<=u'affect': u')\\w+\", line)\n",
    "                    cond = cond.group(0) if cond else \"fixation\"\n",
    "                    if cond == \"NULL\":\n",
    "                        cond = \"silent\"\n",
    "                    sent = re.search(\"(?<=sentence_': u(\\'|\\\"))([\\w ?!.']+)\", line)\n",
    "\n",
    "                    # TODO: some sentences are being cut off\n",
    "                    # see test.tsv\n",
    "                    sent = (sent.group(0) if sent else \"n/a\").strip().strip(\"'\")\n",
    "                    # sentences can also consist of only whitespace\n",
    "                    if not sent:\n",
    "                        sent = \"n/a\"\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(\"Caught error\", str(e))\n",
    "                    print(line)\n",
    "                    continue\n",
    "\n",
    "                conds.append(cond)\n",
    "                sentences.append(sent)\n",
    "        #         if speak_start:\n",
    "        #             speak_start[-1] = speak_start[-1] - onset\n",
    "                onset_timestamp.append(onset)\n",
    "                if not onsets:\n",
    "                    onsets.append('0')\n",
    "                    start = onset\n",
    "                else:\n",
    "                    onsets.append('%.2f' % (onset - start))\n",
    "            dur = [float(y) - float(x) for x,y in zip(onsets,onsets[1:])]\n",
    "            dur.append(np.mean(dur))\n",
    "            speak_start = np.add([float(on) for on in onsets], np.subtract(speak_start_timestamp, onset_timestamp))\n",
    "        #events = (onsets, dur, conds, sentences)\n",
    "        events = pd.DataFrame([onsets, dur, conds, sentences, speak_start]).T\n",
    "        events.columns = ['onset', 'duration', 'trial_type', 'sentence', 'speak_start']\n",
    "        #events = events[events.trial_type != 'neutral'].reset_index(drop=True)\n",
    "\n",
    "        sub = evf['subject']\n",
    "        ses = evf['session']\n",
    "        task = evf['task']\n",
    "        run = int(evf['run'])\n",
    "\n",
    "        events.to_csv(f'test/sub-{sub}_ses-{ses}_task-{task}_run-{run}_events.tsv', index= False, sep=\"\\t\")\n",
    "\n",
    "    \n",
    "    #full_events.append(events)\n",
    "\n",
    "        #dur = [duration] * len(onsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PROJECT_ROOT = '/om/project/voice/bids/data'\n",
    "# pheno_root = '/nese/mit/group/sig/om_projects/voice/rawData/voice856/session001_visit002'\n",
    "# psychopy = f'{pheno_root}/behavioral/20151030121456_voice856_S001_T005_R002_emosent.log'\n",
    "# audio = f'{pheno_root}/audio/voice856_S001_T005_R002_emosent.wav'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subj = 'voice856'\n",
    "# task = 'emosent'\n",
    "# run = 2\n",
    "# ses = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cur_ev = glob.glob(f'/nese/mit/group/sig/om_projects/voice/bids/data/sub-{subj}/ses-{ses}/func/sub-{subj}*task-{task}*run-0{run}*events.tsv')\n",
    "# cur_ev = [f'../../derivatives/events_emosent_112823/sub-{subj}_ses-{ses}_task-{task}_run-0{run}_events.tsv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Have you seen him?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.86</td>\n",
       "      <td>1.1</td>\n",
       "      <td>sad</td>\n",
       "      <td>I can't seem to do well on my exams</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.85</td>\n",
       "      <td>1.1</td>\n",
       "      <td>silent</td>\n",
       "      <td>n/a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.84</td>\n",
       "      <td>1.1</td>\n",
       "      <td>neutral</td>\n",
       "      <td>The airplane is almost full</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15.85</td>\n",
       "      <td>1.1</td>\n",
       "      <td>happy</td>\n",
       "      <td>What joke could be funnier than that?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0    1        2                                      3\n",
       "0      0  1.1  neutral                     Have you seen him?\n",
       "1   3.86  1.1      sad    I can't seem to do well on my exams\n",
       "2   7.85  1.1   silent                                    n/a\n",
       "3  11.84  1.1  neutral            The airplane is almost full\n",
       "4  15.85  1.1    happy  What joke could be funnier than that?"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# logf = grab_file(subj, task, run, ses)\n",
    "# get_emosent(logf).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(0, 8), match='224.4750'>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.search(\"^\\d+.\\d+\", line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fails.txt\r\n",
      "second_level\r\n",
      "sub-voice856_ses-1_task-emosent_rec-unco_run-2_space-fsLR_den-91k_contrast-speechvsil_effect_size.dscalar.nii\r\n",
      "sub-voice856_ses-1_task-emosent_rec-unco_run-2_space-fsLR_den-91k_contrast-speechvsil_effect_variance.dscalar.nii\r\n",
      "sub-voice856_ses-1_task-emosent_rec-unco_run-2_space-fsLR_den-91k_contrast-speechvsil_z_score.dscalar.nii\r\n",
      "sub-voice856_ses-1_task-emosent_rec-unco_run-3_space-fsLR_den-91k_contrast-speechvsil_effect_size.dscalar.nii\r\n",
      "sub-voice856_ses-1_task-emosent_rec-unco_run-3_space-fsLR_den-91k_contrast-speechvsil_effect_variance.dscalar.nii\r\n",
      "sub-voice856_ses-1_task-emosent_rec-unco_run-3_space-fsLR_den-91k_contrast-speechvsil_z_score.dscalar.nii\r\n",
      "sub-voice856_ses-1_task-emosent_run-2_events.tsv\r\n",
      "sub-voice856_ses-1_task-emosent_run-3_events.tsv\r\n"
     ]
    }
   ],
   "source": [
    "!ls test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>onset</th>\n",
       "      <th>duration</th>\n",
       "      <th>trial_type</th>\n",
       "      <th>sentence</th>\n",
       "      <th>speak_start</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>3.88</td>\n",
       "      <td>happy</td>\n",
       "      <td>I really enjoy our family vacations</td>\n",
       "      <td>1.1265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.88</td>\n",
       "      <td>4.00</td>\n",
       "      <td>happy</td>\n",
       "      <td>We had so much fun last night</td>\n",
       "      <td>5.0128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.88</td>\n",
       "      <td>4.00</td>\n",
       "      <td>sad</td>\n",
       "      <td>I'm so sorry for hurting you</td>\n",
       "      <td>9.0129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.88</td>\n",
       "      <td>3.98</td>\n",
       "      <td>silent</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15.86</td>\n",
       "      <td>4.00</td>\n",
       "      <td>sad</td>\n",
       "      <td>He never listens to me anymore</td>\n",
       "      <td>16.9932</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   onset  duration trial_type                             sentence   \n",
       "0   0.00      3.88      happy  I really enjoy our family vacations  \\\n",
       "1   3.88      4.00      happy        We had so much fun last night   \n",
       "2   7.88      4.00        sad         I'm so sorry for hurting you   \n",
       "3  11.88      3.98     silent                                  NaN   \n",
       "4  15.86      4.00        sad       He never listens to me anymore   \n",
       "\n",
       "   speak_start  \n",
       "0       1.1265  \n",
       "1       5.0128  \n",
       "2       9.0129  \n",
       "3      13.0129  \n",
       "4      16.9932  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_table('test/sub-voice856_ses-1_task-emosent_run-2_events.tsv').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>onset</th>\n",
       "      <th>duration</th>\n",
       "      <th>trial_type</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>4</td>\n",
       "      <td>happy</td>\n",
       "      <td>I really enjoy our family vacations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.88</td>\n",
       "      <td>4</td>\n",
       "      <td>happy</td>\n",
       "      <td>We had so much fun last night</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.88</td>\n",
       "      <td>4</td>\n",
       "      <td>sad</td>\n",
       "      <td>I'm so sorry for hurting you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.88</td>\n",
       "      <td>4</td>\n",
       "      <td>silent</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15.86</td>\n",
       "      <td>4</td>\n",
       "      <td>sad</td>\n",
       "      <td>He never listens to me anymore</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   onset  duration trial_type                             sentence\n",
       "0   0.00         4      happy  I really enjoy our family vacations\n",
       "1   3.88         4      happy        We had so much fun last night\n",
       "2   7.88         4        sad         I'm so sorry for hurting you\n",
       "3  11.88         4     silent                                  NaN\n",
       "4  15.86         4        sad       He never listens to me anymore"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_table('../../derivatives/events_emosent_112823/sub-voice856_ses-1_task-emosent_run-01_events.tsv').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>onset</th>\n",
       "      <th>duration</th>\n",
       "      <th>trial_type</th>\n",
       "      <th>sentences</th>\n",
       "      <th>speak_start</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3.88</td>\n",
       "      <td>happy</td>\n",
       "      <td>I really enjoy our family vacations</td>\n",
       "      <td>1.1265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.88</td>\n",
       "      <td>4.0</td>\n",
       "      <td>happy</td>\n",
       "      <td>We had so much fun last night</td>\n",
       "      <td>5.0128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.88</td>\n",
       "      <td>4.0</td>\n",
       "      <td>sad</td>\n",
       "      <td>I'm so sorry for hurting you</td>\n",
       "      <td>9.0129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.88</td>\n",
       "      <td>3.98</td>\n",
       "      <td>silent</td>\n",
       "      <td>n/a</td>\n",
       "      <td>13.0129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15.86</td>\n",
       "      <td>4.0</td>\n",
       "      <td>sad</td>\n",
       "      <td>He never listens to me anymore</td>\n",
       "      <td>16.9932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>19.86</td>\n",
       "      <td>3.99</td>\n",
       "      <td>sad</td>\n",
       "      <td>I miss the trips we used to take</td>\n",
       "      <td>20.9843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>23.85</td>\n",
       "      <td>4.0</td>\n",
       "      <td>neutral</td>\n",
       "      <td>I'm on my way to the meeting</td>\n",
       "      <td>24.9825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>27.85</td>\n",
       "      <td>4.0</td>\n",
       "      <td>happy</td>\n",
       "      <td>You look so excited</td>\n",
       "      <td>28.9825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>31.85</td>\n",
       "      <td>4.0</td>\n",
       "      <td>neutral</td>\n",
       "      <td>I wonder what that is about</td>\n",
       "      <td>32.9823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>35.85</td>\n",
       "      <td>4.0</td>\n",
       "      <td>happy</td>\n",
       "      <td>What could be better?</td>\n",
       "      <td>36.9826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>39.85</td>\n",
       "      <td>4.0</td>\n",
       "      <td>happy</td>\n",
       "      <td>I love spending time with you</td>\n",
       "      <td>40.983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>43.85</td>\n",
       "      <td>4.0</td>\n",
       "      <td>happy</td>\n",
       "      <td>This chicken is excellent</td>\n",
       "      <td>44.983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>47.85</td>\n",
       "      <td>4.0</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Have you seen him?</td>\n",
       "      <td>48.9829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>51.85</td>\n",
       "      <td>3.99</td>\n",
       "      <td>silent</td>\n",
       "      <td>n/a</td>\n",
       "      <td>52.9753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>55.84</td>\n",
       "      <td>4.0</td>\n",
       "      <td>neutral</td>\n",
       "      <td>The airplane is almost full</td>\n",
       "      <td>56.9724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>59.84</td>\n",
       "      <td>4.0</td>\n",
       "      <td>happy</td>\n",
       "      <td>The new version is the best</td>\n",
       "      <td>60.9723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>63.84</td>\n",
       "      <td>4.0</td>\n",
       "      <td>silent</td>\n",
       "      <td>n/a</td>\n",
       "      <td>64.9725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>67.84</td>\n",
       "      <td>4.0</td>\n",
       "      <td>sad</td>\n",
       "      <td>I regret that we broke up</td>\n",
       "      <td>68.9724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>71.84</td>\n",
       "      <td>4.0</td>\n",
       "      <td>happy</td>\n",
       "      <td>That show makes me laugh</td>\n",
       "      <td>72.9727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>75.84</td>\n",
       "      <td>4.0</td>\n",
       "      <td>silent</td>\n",
       "      <td>n/a</td>\n",
       "      <td>76.973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>79.84</td>\n",
       "      <td>4.0</td>\n",
       "      <td>happy</td>\n",
       "      <td>That magazine is my favorite</td>\n",
       "      <td>80.973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>83.84</td>\n",
       "      <td>3.99</td>\n",
       "      <td>silent</td>\n",
       "      <td>n/a</td>\n",
       "      <td>84.9662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>87.83</td>\n",
       "      <td>3.99</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Can you hear me?</td>\n",
       "      <td>88.9545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>91.82</td>\n",
       "      <td>3.99</td>\n",
       "      <td>sad</td>\n",
       "      <td>I miss the time we spent together</td>\n",
       "      <td>92.9423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>95.81</td>\n",
       "      <td>4.0</td>\n",
       "      <td>silent</td>\n",
       "      <td>n/a</td>\n",
       "      <td>96.9423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>99.81</td>\n",
       "      <td>4.0</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Maybe tomorrow it will be cold</td>\n",
       "      <td>100.9425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>103.81</td>\n",
       "      <td>4.0</td>\n",
       "      <td>neutral</td>\n",
       "      <td>I would like a new alarm clock</td>\n",
       "      <td>104.9427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>107.81</td>\n",
       "      <td>4.0</td>\n",
       "      <td>sad</td>\n",
       "      <td>It's terrible that such a thing could happen</td>\n",
       "      <td>108.943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>111.81</td>\n",
       "      <td>4.0</td>\n",
       "      <td>sad</td>\n",
       "      <td>I can't seem to do well on my exams</td>\n",
       "      <td>112.9429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>115.81</td>\n",
       "      <td>4.0</td>\n",
       "      <td>silent</td>\n",
       "      <td>n/a</td>\n",
       "      <td>116.943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>119.81</td>\n",
       "      <td>3.99</td>\n",
       "      <td>sad</td>\n",
       "      <td>Please forgive me</td>\n",
       "      <td>120.9353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>123.80</td>\n",
       "      <td>4.0</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Can you call me tomorrow?</td>\n",
       "      <td>124.9255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>127.80</td>\n",
       "      <td>4.0</td>\n",
       "      <td>silent</td>\n",
       "      <td>n/a</td>\n",
       "      <td>128.9321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>131.80</td>\n",
       "      <td>4.0</td>\n",
       "      <td>sad</td>\n",
       "      <td>If only I could go back</td>\n",
       "      <td>132.9324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>135.80</td>\n",
       "      <td>4.0</td>\n",
       "      <td>sad</td>\n",
       "      <td>If only I hadn't said those things</td>\n",
       "      <td>136.9322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>139.80</td>\n",
       "      <td>4.0</td>\n",
       "      <td>silent</td>\n",
       "      <td>n/a</td>\n",
       "      <td>140.9327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>143.80</td>\n",
       "      <td>4.0</td>\n",
       "      <td>happy</td>\n",
       "      <td>I always enjoy when she visits</td>\n",
       "      <td>144.933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>147.80</td>\n",
       "      <td>4.0</td>\n",
       "      <td>neutral</td>\n",
       "      <td>I think I have a doctor</td>\n",
       "      <td>148.9331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>151.80</td>\n",
       "      <td>3.99</td>\n",
       "      <td>silent</td>\n",
       "      <td>n/a</td>\n",
       "      <td>152.9262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>155.79</td>\n",
       "      <td>3.99</td>\n",
       "      <td>happy</td>\n",
       "      <td>That was better than the first time</td>\n",
       "      <td>156.9144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>159.78</td>\n",
       "      <td>3.99</td>\n",
       "      <td>sad</td>\n",
       "      <td>My best friend moved away</td>\n",
       "      <td>160.9023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>163.77</td>\n",
       "      <td>4.0</td>\n",
       "      <td>happy</td>\n",
       "      <td>You look wonderful</td>\n",
       "      <td>164.9025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>167.77</td>\n",
       "      <td>4.0</td>\n",
       "      <td>neutral</td>\n",
       "      <td>We'll stop in a couple of minutes</td>\n",
       "      <td>168.9025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>171.77</td>\n",
       "      <td>4.0</td>\n",
       "      <td>silent</td>\n",
       "      <td>n/a</td>\n",
       "      <td>172.9026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>175.77</td>\n",
       "      <td>4.0</td>\n",
       "      <td>neutral</td>\n",
       "      <td>How did he know that?</td>\n",
       "      <td>176.903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>179.77</td>\n",
       "      <td>4.0</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Don't forget a jacket</td>\n",
       "      <td>180.903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>183.77</td>\n",
       "      <td>3.995</td>\n",
       "      <td>sad</td>\n",
       "      <td>That movie made me cry</td>\n",
       "      <td>184.903</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     onset duration trial_type                                     sentences   \n",
       "0        0     3.88      happy           I really enjoy our family vacations  \\\n",
       "1     3.88      4.0      happy                 We had so much fun last night   \n",
       "2     7.88      4.0        sad                  I'm so sorry for hurting you   \n",
       "3    11.88     3.98     silent                                           n/a   \n",
       "4    15.86      4.0        sad                He never listens to me anymore   \n",
       "5    19.86     3.99        sad              I miss the trips we used to take   \n",
       "6    23.85      4.0    neutral                  I'm on my way to the meeting   \n",
       "7    27.85      4.0      happy                           You look so excited   \n",
       "8    31.85      4.0    neutral                   I wonder what that is about   \n",
       "9    35.85      4.0      happy                         What could be better?   \n",
       "10   39.85      4.0      happy                 I love spending time with you   \n",
       "11   43.85      4.0      happy                     This chicken is excellent   \n",
       "12   47.85      4.0    neutral                            Have you seen him?   \n",
       "13   51.85     3.99     silent                                           n/a   \n",
       "14   55.84      4.0    neutral                   The airplane is almost full   \n",
       "15   59.84      4.0      happy                   The new version is the best   \n",
       "16   63.84      4.0     silent                                           n/a   \n",
       "17   67.84      4.0        sad                     I regret that we broke up   \n",
       "18   71.84      4.0      happy                      That show makes me laugh   \n",
       "19   75.84      4.0     silent                                           n/a   \n",
       "20   79.84      4.0      happy                  That magazine is my favorite   \n",
       "21   83.84     3.99     silent                                           n/a   \n",
       "22   87.83     3.99    neutral                              Can you hear me?   \n",
       "23   91.82     3.99        sad             I miss the time we spent together   \n",
       "24   95.81      4.0     silent                                           n/a   \n",
       "25   99.81      4.0    neutral                Maybe tomorrow it will be cold   \n",
       "26  103.81      4.0    neutral                I would like a new alarm clock   \n",
       "27  107.81      4.0        sad  It's terrible that such a thing could happen   \n",
       "28  111.81      4.0        sad           I can't seem to do well on my exams   \n",
       "29  115.81      4.0     silent                                           n/a   \n",
       "30  119.81     3.99        sad                             Please forgive me   \n",
       "31  123.80      4.0    neutral                     Can you call me tomorrow?   \n",
       "32  127.80      4.0     silent                                           n/a   \n",
       "33  131.80      4.0        sad                       If only I could go back   \n",
       "34  135.80      4.0        sad            If only I hadn't said those things   \n",
       "35  139.80      4.0     silent                                           n/a   \n",
       "36  143.80      4.0      happy                I always enjoy when she visits   \n",
       "37  147.80      4.0    neutral                       I think I have a doctor   \n",
       "38  151.80     3.99     silent                                           n/a   \n",
       "39  155.79     3.99      happy           That was better than the first time   \n",
       "40  159.78     3.99        sad                     My best friend moved away   \n",
       "41  163.77      4.0      happy                            You look wonderful   \n",
       "42  167.77      4.0    neutral             We'll stop in a couple of minutes   \n",
       "43  171.77      4.0     silent                                           n/a   \n",
       "44  175.77      4.0    neutral                         How did he know that?   \n",
       "45  179.77      4.0    neutral                         Don't forget a jacket   \n",
       "46  183.77    3.995        sad                        That movie made me cry   \n",
       "\n",
       "   speak_start  \n",
       "0       1.1265  \n",
       "1       5.0128  \n",
       "2       9.0129  \n",
       "3      13.0129  \n",
       "4      16.9932  \n",
       "5      20.9843  \n",
       "6      24.9825  \n",
       "7      28.9825  \n",
       "8      32.9823  \n",
       "9      36.9826  \n",
       "10      40.983  \n",
       "11      44.983  \n",
       "12     48.9829  \n",
       "13     52.9753  \n",
       "14     56.9724  \n",
       "15     60.9723  \n",
       "16     64.9725  \n",
       "17     68.9724  \n",
       "18     72.9727  \n",
       "19      76.973  \n",
       "20      80.973  \n",
       "21     84.9662  \n",
       "22     88.9545  \n",
       "23     92.9423  \n",
       "24     96.9423  \n",
       "25    100.9425  \n",
       "26    104.9427  \n",
       "27     108.943  \n",
       "28    112.9429  \n",
       "29     116.943  \n",
       "30    120.9353  \n",
       "31    124.9255  \n",
       "32    128.9321  \n",
       "33    132.9324  \n",
       "34    136.9322  \n",
       "35    140.9327  \n",
       "36     144.933  \n",
       "37    148.9331  \n",
       "38    152.9262  \n",
       "39    156.9144  \n",
       "40    160.9023  \n",
       "41    164.9025  \n",
       "42    168.9025  \n",
       "43    172.9026  \n",
       "44     176.903  \n",
       "45     180.903  \n",
       "46     184.903  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_events[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[39.5709,\n",
       " 43.4267,\n",
       " 47.4191,\n",
       " 51.4112,\n",
       " 55.4163,\n",
       " 59.4149,\n",
       " 63.4142,\n",
       " 67.414,\n",
       " 71.4147,\n",
       " 75.4152,\n",
       " 79.4079,\n",
       " 83.4064,\n",
       " 87.4051,\n",
       " 91.4038,\n",
       " 95.4025,\n",
       " 99.4022,\n",
       " 103.4025,\n",
       " 107.403,\n",
       " 111.4035,\n",
       " 115.3957,\n",
       " 119.3943,\n",
       " 123.393,\n",
       " 127.3917,\n",
       " 131.3909,\n",
       " 135.3906,\n",
       " 139.3915,\n",
       " 143.3918,\n",
       " 147.3924,\n",
       " 151.3836,\n",
       " 155.3822,\n",
       " 159.3807,\n",
       " 163.3794,\n",
       " 167.3792,\n",
       " 171.3794,\n",
       " 175.38,\n",
       " 179.3806,\n",
       " 183.3727,\n",
       " 187.3652,\n",
       " 191.3534,\n",
       " 195.3521,\n",
       " 199.3513,\n",
       " 203.351,\n",
       " 207.3515,\n",
       " 211.3521,\n",
       " 215.3529,\n",
       " 219.3534,\n",
       " 223.354]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onset_timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "speak_start[-1] = speak_start[-1] - onset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0', '3.86', '7.85', '11.84', '15.85']"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onsets[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([40.6923, 40.6924, 40.6936, 40.693 , 40.6983, 40.707 , 40.7066,\n",
       "       40.7066, 40.7072, 40.7017, 40.7003, 40.6989, 40.7076, 40.7061,\n",
       "       40.7052, 40.7048, 40.7054, 40.706 , 40.6996, 40.7081, 40.7068,\n",
       "       40.7054, 40.704 , 40.7036, 40.7036, 40.7042, 40.7049, 40.6973,\n",
       "       40.7059, 40.7046, 40.7032, 40.7022, 40.7019, 40.7025, 40.7031,\n",
       "       40.6965, 40.6975, 40.6972, 40.7057, 40.7044, 40.704 , 40.704 ,\n",
       "       40.7046, 40.7051, 40.7057, 40.7064, 40.695 ])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.subtract(speak_start,[float(o) for o in onsets])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(logf, encoding='utf-8') as fp:\n",
    "    conds = []\n",
    "    onsets = []\n",
    "    sentences = []\n",
    "    speak_start = []\n",
    "    # time when first volume is acquired\n",
    "    start = -1\n",
    "    a = [l for l in fp if 'polygon: autoDraw = True' in l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "224.475"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float(re.search(\"^\\d+.\\d+\", line).group(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'224.4750 \\tEXP \\ttext_3: autoDraw = True\\n'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speak_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.9952173913043483"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([float(y) - float(x) for x,y in zip(onsets,onsets[1:])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(onsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43.4267"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_emosent(logf, duration='1.1', outfile=None):\n",
    "    \"\"\"Parse Emotional Sentences log file and return onset/condition/duration/sentence\"\"\"\n",
    "    \n",
    "    with open(logf, encoding='utf-8') as fp:\n",
    "        conds = []\n",
    "        onsets = []\n",
    "        sentences = []\n",
    "        # time when first volume is acquired\n",
    "        start = -1\n",
    "\n",
    "        for line in fp:\n",
    "            # we only care about new trials\n",
    "            if 'New trial' not in line:\n",
    "                continue\n",
    "            try:\n",
    "                # onset time\n",
    "                onset = float(re.search(\"^\\d+.\\d+\", line).group(0))\n",
    "                # condition and sentences are coded as blank\n",
    "                cond = re.search(\"(?<=u'affect': u')\\w+\", line)\n",
    "                cond = cond.group(0) if cond else \"fixation\"\n",
    "                if cond == \"NULL\":\n",
    "                    cond = \"silent\"\n",
    "                sent = re.search(\"(?<=sentence_': u(\\'|\\\"))([\\w ?!.']+)\", line)\n",
    "                # TODO: some sentences are being cut off\n",
    "                # see test.tsv\n",
    "                sent = (sent.group(0) if sent else \"n/a\").strip().strip(\"'\")\n",
    "                # sentences can also consist of only whitespace\n",
    "                if not sent:\n",
    "                    sent = \"n/a\"\n",
    "\n",
    "            except Exception as e:\n",
    "                print(\"Caught error\", str(e))\n",
    "                print(line)\n",
    "                continue\n",
    "\n",
    "            conds.append(cond)\n",
    "            sentences.append(sent)\n",
    "            if not onsets:\n",
    "                onsets.append('0')\n",
    "                start = onset\n",
    "            else:\n",
    "                onsets.append('%.2f' % (onset - start))\n",
    "            \n",
    "        dur = [duration] * len(onsets)\n",
    "        \n",
    "    #events = (onsets, dur, conds, sentences)\n",
    "    events = pd.DataFrame([onsets, dur, conds, sentences]).T\n",
    "    if outfile:\n",
    "        write_events(events, outfile, ['sentences'])\n",
    "    return events\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def grab_file(subj, task, run, session=1, ext='log'):\n",
    "    #template = \"/om/project/voice/rawData/{subj}/session00{ses}_visi*/behavioral/\"\n",
    "    template = '/nese/mit/group/sig/om_projects/voice/rawData/{subj}/session00{ses}_visi*/behavioral/'\n",
    "    \n",
    "    #we dont hit this\n",
    "    if ext == 'mat':\n",
    "        template += \"*_run{run}.{ext}\"\n",
    "    \n",
    "    #grabs the pyschopy log file\n",
    "    else:\n",
    "        template += \"*_R00{run}_{task}*{ext}\"\n",
    "    template = template.format(subj=subj, ses=session, run=run, task=task, ext=ext)\n",
    "    for fl in iglob(template):\n",
    "        return fl\n",
    "\n",
    "def test_emosent():\n",
    "    ons, dur, con, sen = get_emosent(grab_file('voice969', 'emosent', 1))\n",
    "    assert all(ons)\n",
    "    assert all(dur)\n",
    "    assert all(con)\n",
    "    assert all(sen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for subj in layout.get_subjects():\n",
    "#     for ses in layout.get_sessions():\n",
    "        \n",
    "#         fls = layout.get(\n",
    "#                 subject=subj, \n",
    "#                 session=ses, \n",
    "#                 task='emosent', \n",
    "#                 suffix='bold', \n",
    "#                 extensions=['nii.gz']\n",
    "#         )\n",
    "        \n",
    "#         # too many or too few runs\n",
    "#         if not 0 < len(fls) < 3:\n",
    "#             print(\"Skipping %s-%s\" % (subj, ses))\n",
    "#             continue\n",
    "        \n",
    "#         print(\"Processing %s-%s\" % (subj, ses))\n",
    "#         for fl in fls:\n",
    "#             # find matching rawdata\n",
    "#             raw_fl = grab_file(subj, fl.task, fl.run, ses)\n",
    "#             if not raw_fl:\n",
    "#                 continue\n",
    "            \n",
    "#             event_fl = op.join(fl.dirname, fl.filename.replace('bold.nii.gz', 'events.tsv'))\n",
    "#             events = get_emosent(raw_fl, outfile=event_fl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "PROJECT_ROOT = '/om/project/voice/bids/data'\n",
    "\n",
    "\n",
    "def write_events(events, outfile, xfields=None):\n",
    "    fields = ['onset', 'duration', 'trial_type']\n",
    "    if isinstance(xfields, list):\n",
    "        fields += xfields\n",
    "\n",
    "    with open(outfile, 'w') as tsv:\n",
    "        tsvwriter = writer(tsv, delimiter='\\t')\n",
    "        tsvwriter.writerow(fields)\n",
    "        for i in range(len(events[0])):\n",
    "            tsvwriter.writerow([ev[i] for ev in events])    \n",
    "    return outfile\n",
    "\n",
    "\n",
    "def get_pataka(logf, duration='5.0', outfile=None):\n",
    "    \"\"\"Parse PaTaKa (pataka) log file and return onsets/duration/conditions\"\"\"\n",
    "    \n",
    "    with open(logf) as fp:\n",
    "        conds = []\n",
    "        onsets = []\n",
    "        # time when first volume is acquired\n",
    "        start = -1\n",
    "\n",
    "        for line in fp:\n",
    "            # we only care about new trials\n",
    "            if 'New trial' not in line:\n",
    "                continue\n",
    "            try:\n",
    "                # condition type\n",
    "                cond = re.search(\"(?<=u'instr': u')\\w+\", line).group(0)\n",
    "                # onset time\n",
    "                onset = float(re.search(\"^\\d+.\\d+\", line).group(0))\n",
    "            except Exception as e:\n",
    "                print(\"Caught error\", str(e))\n",
    "                continue\n",
    "\n",
    "            conds.append(cond)\n",
    "            if start == -1:\n",
    "                onsets.append('0')\n",
    "                start = onset\n",
    "            else:\n",
    "                onsets.append('%.2f' % (onset - start))\n",
    "\n",
    "    durs = [duration] * len(onsets)\n",
    "    events = (onsets, durs, conds)\n",
    "    if outfile:\n",
    "        write_events(events, outfile)\n",
    "    return events\n",
    "\n",
    "\n",
    "def get_pitch_sentences(logf, duration='1.1', write=False):\n",
    "    \"\"\"Parse Sentences (pitchsent) log file and return onsets/durations/conditions/sentence\"\"\"\n",
    "    \n",
    "    with open(logf, encoding='utf-8') as fp:\n",
    "        conds = []\n",
    "        onsets = []\n",
    "        sentences = []\n",
    "        # time when first volume is acquired\n",
    "        start = -1\n",
    "\n",
    "        for line in fp:\n",
    "            # we only care about new trials\n",
    "            if 'New trial' not in line:\n",
    "                continue\n",
    "            try:\n",
    "                # onset time\n",
    "                onset = float(re.search(\"^\\d+.\\d+\", line).group(0))\n",
    "                # condition and sentences are coded as blank\n",
    "                cond = re.search(\"(?<=u'pitch': u')\\w+\", line)\n",
    "                cond = cond.group(0) if cond else \"silent\"\n",
    "                sent = re.search(\"(?<=sentence': u(\\'|\\\"))([\\w ?!.']+)\", line)\n",
    "                sent = (sent.group(0) if sent else \"n/a\").strip().strip(\"'\")\n",
    "                # sentences can also consist of only whitespace\n",
    "                if not sent:\n",
    "                    sent = \"n/a\"\n",
    "\n",
    "            except Exception as e:\n",
    "                print(\"Caught error\", str(e))\n",
    "                print(line)\n",
    "                continue\n",
    "\n",
    "            # do not write missing sentences\n",
    "            if sent == 'n/a':\n",
    "                continue\n",
    "            conds.append(cond)\n",
    "            sentences.append(sent)\n",
    "            if not onsets:\n",
    "                onsets.append('0')\n",
    "                start = onset\n",
    "            else:\n",
    "                onsets.append('%.2f' % (onset - start))\n",
    "            \n",
    "        dur = [duration] * len(onsets)\n",
    "    return onsets, dur, conds, sentences\n",
    "\n",
    "\n",
    "def get_nwr(csvf, duration='1.1', write=False):\n",
    "    \"\"\"Parse Nonword repetition (nwr) CSV file and return onset/duration/condition/word\"\"\"\n",
    "    df = pd.read_csv(csvf)\n",
    "    \n",
    "    # extract when first volume is collected\n",
    "    start = df.loc[:, 'wordonset'][0]\n",
    "    \n",
    "    # adjust for late start\n",
    "    df['wordonset'] = df['wordonset'] - start\n",
    "    \n",
    "    # replace Silent with n/a\n",
    "    # TODO: drop Silent instead\n",
    "    df['Word'].replace(to_replace=\"Silent\",\n",
    "                       value=\"n/a\",\n",
    "                       inplace=True)\n",
    "    \n",
    "    dur = [duration] * len(df['wordonset'].tolist())\n",
    "    \n",
    "    # round onsets and convert to string\n",
    "    df = df.round({'wordonset': 2}).astype({'wordonset': str})\n",
    "\n",
    "    return df['wordonset'].tolist(), dur, df['Syllables'].tolist(), df['Word'].tolist()\n",
    "\n",
    "\n",
    "def get_face(logf, duration='1.1', outfile=None):\n",
    "    \"\"\"Parse face mat file and return onset/condition/duration\"\"\"\n",
    "    \n",
    "    def get_val(el):\n",
    "        \"\"\"Recursive traversal of element until returns a single value\"\"\"\n",
    "        if not hasattr(el, '__iter__') or isinstance(el, str):\n",
    "            return el\n",
    "        try:\n",
    "            el[0]\n",
    "        except TypeError:\n",
    "            return el\n",
    "        return get_val(el[0])\n",
    "    \n",
    "    conds = []\n",
    "    onsets = []\n",
    "    \n",
    "    mat = loadmat(logf)\n",
    "    data = mat['runData']\n",
    "    assert data is not None\n",
    "\n",
    "    for val in data:\n",
    "        conds.append(get_val(val[1]))\n",
    "        onsets.append('%.2f' % get_val(val[2]))\n",
    "        \n",
    "    durs = [duration] * len(onsets)\n",
    "    events = (onsets, durs, conds)\n",
    "    if outfile:\n",
    "        write_events(events, outfile)\n",
    "    return events\n",
    "\n",
    "\n",
    "def get_emosent(logf, duration='1.1', outfile=None):\n",
    "    \"\"\"Parse Emotional Sentences log file and return onset/condition/duration/sentence\"\"\"\n",
    "    \n",
    "    with open(logf, encoding='utf-8') as fp:\n",
    "        conds = []\n",
    "        onsets = []\n",
    "        sentences = []\n",
    "        # time when first volume is acquired\n",
    "        start = -1\n",
    "\n",
    "        for line in fp:\n",
    "            # we only care about new trials\n",
    "            if 'New trial' not in line:\n",
    "                continue\n",
    "            try:\n",
    "                # onset time\n",
    "                onset = float(re.search(\"^\\d+.\\d+\", line).group(0))\n",
    "                # condition and sentences are coded as blank\n",
    "                cond = re.search(\"(?<=u'affect': u')\\w+\", line)\n",
    "                cond = cond.group(0) if cond else \"fixation\"\n",
    "                if cond == \"NULL\":\n",
    "                    cond = \"silent\"\n",
    "                sent = re.search(\"(?<=sentence_': u(\\'|\\\"))([\\w ?!.']+)\", line)\n",
    "                # TODO: some sentences are being cut off\n",
    "                # see test.tsv\n",
    "                sent = (sent.group(0) if sent else \"n/a\").strip().strip(\"'\")\n",
    "                # sentences can also consist of only whitespace\n",
    "                if not sent:\n",
    "                    sent = \"n/a\"\n",
    "\n",
    "            except Exception as e:\n",
    "                print(\"Caught error\", str(e))\n",
    "                print(line)\n",
    "                continue\n",
    "\n",
    "            conds.append(cond)\n",
    "            sentences.append(sent)\n",
    "            if not onsets:\n",
    "                onsets.append('0')\n",
    "                start = onset\n",
    "            else:\n",
    "                onsets.append('%.2f' % (onset - start))\n",
    "            \n",
    "        dur = [duration] * len(onsets)\n",
    "        \n",
    "    events = (onsets, dur, conds, sentences)\n",
    "    if outfile:\n",
    "        write_events(events, outfile, ['sentences'])\n",
    "    return events\n",
    "\n",
    "\n",
    "def get_vowel(logf, duration='1.1', outfile=None):\n",
    "    \"\"\"Parse vowels and return onset/condition/duration/vowel\"\"\"\n",
    "    with open(logf, encoding='utf-8') as fp:\n",
    "        conds = []\n",
    "        onsets = []\n",
    "        vowels = []\n",
    "        # time when first volume is acquired\n",
    "        start = -1\n",
    "\n",
    "        for line in fp:\n",
    "            # we only care about new trials\n",
    "            if 'New trial' not in line:\n",
    "                continue\n",
    "            try:\n",
    "                # onset time\n",
    "                onset = float(re.search(\"^\\d+.\\d+\", line).group(0))\n",
    "                # condition and sentences are coded as blank\n",
    "                prompt = re.search(\"(?<=u'vowel': u')[\\w ]+\", line)\n",
    "                # prompt is made up of {pitch} {vowel}\n",
    "                if prompt and prompt.group(0).strip():\n",
    "                    cond, vowel = prompt.group(0).split()\n",
    "                else:\n",
    "                    cond = \"silent\"\n",
    "                    vowel = \"n/a\"\n",
    "\n",
    "            except Exception as e:\n",
    "                print(\"Caught error\", str(e))\n",
    "                print(line)\n",
    "                continue\n",
    "\n",
    "            conds.append(cond)\n",
    "            vowels.append(vowel)\n",
    "            if start == -1:\n",
    "                onsets.append('0')\n",
    "                start = onset\n",
    "            else:\n",
    "                onsets.append('%.2f' % (onset - start))\n",
    "            \n",
    "        dur = [duration] * len(onsets)\n",
    "        \n",
    "    events = (onsets, dur, conds, vowels)\n",
    "    if outfile:\n",
    "        write_events(events, outfile, [\"vowel\"])\n",
    "    return events\n",
    "\n",
    "\n",
    "def get_pitchnw(logf, duration='1.1', outfile=None):\n",
    "    \"\"\"Parse vowels and return onset/condition/duration/pitch\"\"\"\n",
    "\n",
    "    with open(logf, encoding='utf-8') as fp:\n",
    "        conds = []\n",
    "        onsets = []\n",
    "        words = []\n",
    "        # time when first volume is acquired\n",
    "        start = -1\n",
    "\n",
    "        onset_re = re.compile(\"^\\d+.\\d+\")\n",
    "        prompt_re = re.compile(\"(?<=u'word': u')[\\w?!.]+\")\n",
    "        for line in fp:\n",
    "            # we only care about new trials\n",
    "            if 'New trial' not in line:\n",
    "                continue\n",
    "            try:\n",
    "                # onset time\n",
    "                onset = float(onset_re.search(line).group(0))\n",
    "                # condition and sentences are coded as blank\n",
    "                prompt = prompt_re.search(line)\n",
    "                # prompt is made up of {pitch} {vowel}\n",
    "                if prompt and prompt.group(0).strip():\n",
    "                    word = prompt.group(0)\n",
    "                    if word[-1] == \".\":\n",
    "                        cond = \"statement\"\n",
    "                    elif word[-1] == \"?\":\n",
    "                        cond = \"question\"\n",
    "                    elif word[-1] == \"!\":\n",
    "                        cond = \"exclamation\"\n",
    "                    word = word[:-1]\n",
    "                else:\n",
    "                    cond = \"silent\"\n",
    "                    word = \"n/a\"\n",
    "\n",
    "            except Exception as e:\n",
    "                print(\"Caught error\", str(e))\n",
    "                print(line)\n",
    "                continue\n",
    "\n",
    "            conds.append(cond)\n",
    "            words.append(word)\n",
    "            if start == -1:\n",
    "                onsets.append('0')\n",
    "                start = onset\n",
    "            else:\n",
    "                onsets.append('%.2f' % (onset - start))\n",
    "            \n",
    "        dur = [duration] * len(onsets)\n",
    "        \n",
    "    events = (onsets, dur, conds, words)\n",
    "    if outfile:\n",
    "        write_events(events, outfile, [\"nonword\"])\n",
    "    return events\n",
    "\n",
    "# TODO: other tasks\n",
    "# 8 - movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "############### \n",
    "#    tests\n",
    "###############\n",
    "\n",
    "def grab_file(subj, task, run, session=1, ext='log'):\n",
    "    template = \"/om/project/voice/rawData/{subj}/session00{ses}_visi*/behavioral/\"\n",
    "    if ext == 'mat':\n",
    "        template += \"*_run{run}.{ext}\"\n",
    "    else:\n",
    "        template += \"*_R00{run}_{task}*{ext}\"\n",
    "    template = template.format(subj=subj, ses=session, run=run, task=task, ext=ext)\n",
    "    for fl in iglob(template):\n",
    "        return fl\n",
    "\n",
    "\n",
    "def test_pataka():\n",
    "    ons, dur, con = get_pataka(grab_file('voice969', 'pataka', 2))\n",
    "    assert all(ons)\n",
    "    assert all(dur)\n",
    "    assert all(con)\n",
    "    assert len(ons) == len(dur) == len(con)\n",
    "\n",
    "    \n",
    "def test_pitch_sentences():\n",
    "    ons, dur, con, sen = get_pitch_sentences(grab_file('voice969', 'pitchsent', 1))\n",
    "    assert all(con)\n",
    "    assert all(dur)\n",
    "    assert all(ons)\n",
    "    assert all(sen)\n",
    "    assert len(ons) == len(dur) == len(con) == len(sen)\n",
    "    \n",
    "    for c,s in zip(con,sen):\n",
    "        if s == \"n/a\":\n",
    "            assert c == 'silent'\n",
    "    \n",
    "\n",
    "def test_nwr():\n",
    "    ons, dur, con, wrd = get_nwr(grab_file('voice969', 'nwr', 2, ext='csv'))\n",
    "    assert all(con)\n",
    "    assert all(dur)\n",
    "    assert all(ons)\n",
    "    assert all(wrd)\n",
    "    assert len(ons) == len(dur) == len(con) == len(wrd)\n",
    "\n",
    "    \n",
    "def test_face():\n",
    "    ons, dur, con = get_face(grab_file('voice969', 'face', 1, ext='mat'))\n",
    "    assert all(ons)\n",
    "    assert all(dur)\n",
    "    assert all(con)\n",
    "    assert len(ons) == len(dur) == len(con)\n",
    "    \n",
    "\n",
    "def test_emosent():\n",
    "    ons, dur, con, sen = get_emosent(grab_file('voice969', 'emosent', 1))\n",
    "    assert all(ons)\n",
    "    assert all(dur)\n",
    "    assert all(con)\n",
    "    assert all(sen)\n",
    "    \n",
    "def test_vowel():\n",
    "    ons, dur, con, snd = get_vowel(grab_file('voice969', 'vowel', 1))\n",
    "    assert all(ons)\n",
    "    assert all(dur)\n",
    "    assert all(con)\n",
    "    assert all(snd)\n",
    "    assert len(ons) == len(dur) == len(con) == len(snd)\n",
    "    \n",
    "    \n",
    "def test_pitchnw():\n",
    "    ons, dur, con, wrd = get_pitchnw(grab_file('voice969', 'pitchnw', 1))\n",
    "    assert all(ons)\n",
    "    assert all(dur)\n",
    "    assert all(con)\n",
    "    assert all(wrd)\n",
    "    assert len(ons) == len(dur) == len(con) == len(wrd)\n",
    "\n",
    "test_pataka()\n",
    "test_pitch_sentences()\n",
    "test_nwr()\n",
    "test_face()\n",
    "test_emosent()\n",
    "test_vowel()\n",
    "test_pitchnw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layout = BIDSLayout(PROJECT_ROOT, config=['bids'])#, exclude=['derivatives', '.heudiconv', 'code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing voice844-1\n",
      "Skipping voice844-2\n",
      "Processing voice846-1\n",
      "Skipping voice846-2\n",
      "Processing voice849-1\n",
      "Skipping voice849-2\n",
      "Processing voice850-1\n",
      "Skipping voice850-2\n",
      "Processing voice852-1\n",
      "Skipping voice852-2\n",
      "Processing voice854-1\n",
      "Skipping voice854-2\n",
      "Processing voice856-1\n",
      "Skipping voice856-2\n",
      "Processing voice857-1\n",
      "Skipping voice857-2\n",
      "Processing voice859-1\n",
      "Skipping voice859-2\n",
      "Processing voice860-1\n",
      "Skipping voice860-2\n",
      "Processing voice862-1\n",
      "Skipping voice862-2\n",
      "Processing voice863-1\n",
      "Skipping voice863-2\n",
      "Processing voice864-1\n",
      "Skipping voice864-2\n",
      "Processing voice867-1\n",
      "Skipping voice867-2\n",
      "Processing voice872-1\n",
      "Skipping voice872-2\n",
      "Processing voice873-1\n",
      "Skipping voice873-2\n",
      "Processing voice875-1\n",
      "Processing voice875-2\n",
      "Processing voice877-1\n",
      "Skipping voice877-2\n",
      "Processing voice880-1\n",
      "Skipping voice880-2\n",
      "Processing voice884-1\n",
      "Skipping voice884-2\n",
      "Skipping voice886-1\n",
      "Skipping voice886-2\n",
      "Processing voice889-1\n",
      "Processing voice889-2\n",
      "Processing voice891-1\n",
      "Skipping voice891-2\n",
      "Processing voice893-1\n",
      "Processing voice893-2\n",
      "Processing voice895-1\n",
      "Skipping voice895-2\n",
      "Processing voice896-1\n",
      "Skipping voice896-2\n",
      "Processing voice897-1\n",
      "Skipping voice897-2\n",
      "Processing voice898-1\n",
      "Skipping voice898-2\n",
      "Processing voice949-1\n",
      "Skipping voice949-2\n",
      "Processing voice950-1\n",
      "Skipping voice950-2\n",
      "Processing voice951-1\n",
      "Skipping voice951-2\n",
      "Processing voice952-1\n",
      "Skipping voice952-2\n",
      "Processing voice953-1\n",
      "Skipping voice953-2\n",
      "Processing voice954-1\n",
      "Skipping voice954-2\n",
      "Processing voice955-1\n",
      "Skipping voice955-2\n",
      "Processing voice956-1\n",
      "Processing voice956-2\n",
      "Processing voice957-1\n",
      "Skipping voice957-2\n",
      "Processing voice958-1\n",
      "Skipping voice958-2\n",
      "Processing voice960-1\n",
      "Skipping voice960-2\n",
      "Processing voice961-1\n",
      "Skipping voice961-2\n",
      "Processing voice962-1\n",
      "Skipping voice962-2\n",
      "Processing voice963-1\n",
      "Skipping voice963-2\n",
      "Processing voice964-1\n",
      "Skipping voice964-2\n",
      "Skipping voice967-1\n",
      "Skipping voice967-2\n",
      "Processing voice968-1\n",
      "Skipping voice968-2\n",
      "Processing voice969-1\n",
      "Skipping voice969-2\n",
      "Processing voice973-1\n",
      "Skipping voice973-2\n",
      "Processing voice974-1\n",
      "Skipping voice974-2\n",
      "Processing voice975-1\n",
      "Skipping voice975-2\n",
      "Processing voice976-1\n",
      "Skipping voice976-2\n",
      "Processing voice978-1\n",
      "Skipping voice978-2\n",
      "Processing voice979-1\n",
      "Skipping voice979-2\n",
      "Processing voice980-1\n",
      "Skipping voice980-2\n",
      "Processing voice981-1\n",
      "Skipping voice981-2\n",
      "Processing voice982-1\n",
      "Skipping voice982-2\n",
      "Processing voice983-1\n",
      "Skipping voice983-2\n",
      "Processing voice984-1\n",
      "Skipping voice984-2\n",
      "Skipping voice985-1\n",
      "Skipping voice985-2\n",
      "Processing voice986-1\n",
      "Skipping voice986-2\n",
      "Processing voice987-1\n",
      "Skipping voice987-2\n",
      "Processing voice988-1\n",
      "Skipping voice988-2\n",
      "Processing voice989-1\n",
      "Skipping voice989-2\n",
      "Skipping voice990-1\n",
      "Skipping voice990-2\n",
      "Processing voice991-1\n",
      "Skipping voice991-2\n",
      "Processing voice992-1\n",
      "Skipping voice992-2\n",
      "Processing voice993-1\n",
      "Skipping voice993-2\n",
      "Processing voice994-1\n",
      "Skipping voice994-2\n",
      "Processing voice995-1\n",
      "Skipping voice995-2\n",
      "Processing voice996-1\n",
      "Skipping voice996-2\n",
      "Processing voice997-1\n",
      "Skipping voice997-2\n",
      "Processing voice998-1\n",
      "Skipping voice998-2\n",
      "Processing voice999-1\n",
      "Processing voice999-2\n"
     ]
    }
   ],
   "source": [
    "# just grab emosent\n",
    "# updated for pybids 0.8\n",
    "\n",
    "for subj in layout.get_subjects():\n",
    "    for ses in layout.get_sessions():\n",
    "        \n",
    "        fls = layout.get(\n",
    "                subject=subj, \n",
    "                session=ses, \n",
    "                task='emosent', \n",
    "                suffix='bold', \n",
    "                extensions=['nii.gz']\n",
    "        )\n",
    "        \n",
    "        # too many or too few runs\n",
    "        if not 0 < len(fls) < 3:\n",
    "            print(\"Skipping %s-%s\" % (subj, ses))\n",
    "            continue\n",
    "        \n",
    "        print(\"Processing %s-%s\" % (subj, ses))\n",
    "        for fl in fls:\n",
    "            # find matching rawdata\n",
    "            raw_fl = grab_file(subj, fl.task, fl.run, ses)\n",
    "            if not raw_fl:\n",
    "                continue\n",
    "            \n",
    "            event_fl = op.join(fl.dirname, fl.filename.replace('bold.nii.gz', 'events.tsv'))\n",
    "            events = get_emosent(raw_fl, outfile=event_fl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes\n"
     ]
    }
   ],
   "source": [
    "if not 0 < 0 < 4:\n",
    "    print('yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/om/project/voice/bids/data/sub-voice844/ses-1/func/sub-voice844_ses-1_task-emosent_run-01_events.tsv'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "event_fl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = layout.get(subject='voice969', session=1, task='emosent', suffix='bold', extensions=['nii.gz'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fl = '/om/project/voice/rawData/voice969/session001_visit002/behavioral/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['0',\n",
       "  '1.88',\n",
       "  '3.88',\n",
       "  '5.88',\n",
       "  '7.88',\n",
       "  '9.88',\n",
       "  '11.88',\n",
       "  '13.88',\n",
       "  '15.88',\n",
       "  '17.88',\n",
       "  '19.88',\n",
       "  '21.88',\n",
       "  '23.87',\n",
       "  '25.86',\n",
       "  '27.85',\n",
       "  '29.85',\n",
       "  '31.85',\n",
       "  '33.85',\n",
       "  '35.85',\n",
       "  '37.86',\n",
       "  '39.85',\n",
       "  '41.85',\n",
       "  '43.85',\n",
       "  '45.85',\n",
       "  '47.85',\n",
       "  '49.85',\n",
       "  '51.85',\n",
       "  '53.85',\n",
       "  '55.85',\n",
       "  '57.84',\n",
       "  '59.84',\n",
       "  '61.83',\n",
       "  '63.83',\n",
       "  '65.83',\n",
       "  '67.82',\n",
       "  '69.82',\n",
       "  '71.82',\n",
       "  '73.82',\n",
       "  '75.82',\n",
       "  '77.82',\n",
       "  '79.82',\n",
       "  '81.82',\n",
       "  '83.82',\n",
       "  '85.82',\n",
       "  '87.82',\n",
       "  '89.82',\n",
       "  '91.82',\n",
       "  '93.81',\n",
       "  '95.80',\n",
       "  '97.80',\n",
       "  '99.80',\n",
       "  '101.80',\n",
       "  '103.80',\n",
       "  '105.80',\n",
       "  '107.79',\n",
       "  '109.80',\n",
       "  '111.79',\n",
       "  '113.79',\n",
       "  '115.79',\n",
       "  '117.79',\n",
       "  '119.80',\n",
       "  '121.79',\n",
       "  '123.79',\n",
       "  '125.79',\n",
       "  '127.78',\n",
       "  '129.77',\n",
       "  '131.77',\n",
       "  '133.77',\n",
       "  '135.77',\n",
       "  '137.77',\n",
       "  '139.77',\n",
       "  '141.77',\n",
       "  '143.77',\n",
       "  '145.77',\n",
       "  '147.77',\n",
       "  '149.77',\n",
       "  '151.77',\n",
       "  '153.77',\n",
       "  '155.77',\n",
       "  '157.77',\n",
       "  '159.76',\n",
       "  '161.75',\n",
       "  '163.74',\n",
       "  '165.74',\n",
       "  '167.74',\n",
       "  '169.74',\n",
       "  '171.74',\n",
       "  '173.74',\n",
       "  '175.74',\n",
       "  '177.74',\n",
       "  '179.74',\n",
       "  '181.74',\n",
       "  '183.74',\n",
       "  '185.74',\n",
       "  '187.74',\n",
       "  '189.74',\n",
       "  '191.74',\n",
       "  '193.75',\n",
       "  '195.75'],\n",
       " ['1.1',\n",
       "  '1.1',\n",
       "  '1.1',\n",
       "  '1.1',\n",
       "  '1.1',\n",
       "  '1.1',\n",
       "  '1.1',\n",
       "  '1.1',\n",
       "  '1.1',\n",
       "  '1.1',\n",
       "  '1.1',\n",
       "  '1.1',\n",
       "  '1.1',\n",
       "  '1.1',\n",
       "  '1.1',\n",
       "  '1.1',\n",
       "  '1.1',\n",
       "  '1.1',\n",
       "  '1.1',\n",
       "  '1.1',\n",
       "  '1.1',\n",
       "  '1.1',\n",
       "  '1.1',\n",
       "  '1.1',\n",
       "  '1.1',\n",
       "  '1.1',\n",
       "  '1.1',\n",
       "  '1.1',\n",
       "  '1.1',\n",
       "  '1.1',\n",
       "  '1.1',\n",
       "  '1.1',\n",
       "  '1.1',\n",
       "  '1.1',\n",
       "  '1.1',\n",
       "  '1.1',\n",
       "  '1.1',\n",
       "  '1.1',\n",
       "  '1.1',\n",
       "  '1.1',\n",
       "  '1.1',\n",
       "  '1.1',\n",
       "  '1.1',\n",
       "  '1.1',\n",
       "  '1.1',\n",
       "  '1.1',\n",
       "  '1.1',\n",
       "  '1.1',\n",
       "  '1.1',\n",
       "  '1.1',\n",
       "  '1.1',\n",
       "  '1.1',\n",
       "  '1.1',\n",
       "  '1.1',\n",
       "  '1.1',\n",
       "  '1.1',\n",
       "  '1.1',\n",
       "  '1.1',\n",
       "  '1.1',\n",
       "  '1.1',\n",
       "  '1.1',\n",
       "  '1.1',\n",
       "  '1.1',\n",
       "  '1.1',\n",
       "  '1.1',\n",
       "  '1.1',\n",
       "  '1.1',\n",
       "  '1.1',\n",
       "  '1.1',\n",
       "  '1.1',\n",
       "  '1.1',\n",
       "  '1.1',\n",
       "  '1.1',\n",
       "  '1.1',\n",
       "  '1.1',\n",
       "  '1.1',\n",
       "  '1.1',\n",
       "  '1.1',\n",
       "  '1.1',\n",
       "  '1.1',\n",
       "  '1.1',\n",
       "  '1.1',\n",
       "  '1.1',\n",
       "  '1.1',\n",
       "  '1.1',\n",
       "  '1.1',\n",
       "  '1.1',\n",
       "  '1.1',\n",
       "  '1.1',\n",
       "  '1.1',\n",
       "  '1.1',\n",
       "  '1.1',\n",
       "  '1.1',\n",
       "  '1.1',\n",
       "  '1.1',\n",
       "  '1.1',\n",
       "  '1.1',\n",
       "  '1.1',\n",
       "  '1.1'],\n",
       " ['exclamation',\n",
       "  'question',\n",
       "  'statement',\n",
       "  'exclamation',\n",
       "  'exclamation',\n",
       "  'statement',\n",
       "  'question',\n",
       "  'question',\n",
       "  'statement',\n",
       "  'exclamation',\n",
       "  'question',\n",
       "  'exclamation',\n",
       "  'exclamation',\n",
       "  'question',\n",
       "  'statement',\n",
       "  'exclamation',\n",
       "  'exclamation',\n",
       "  'question',\n",
       "  'question',\n",
       "  'statement',\n",
       "  'exclamation',\n",
       "  'statement',\n",
       "  'exclamation',\n",
       "  'statement',\n",
       "  'question',\n",
       "  'statement',\n",
       "  'statement',\n",
       "  'question',\n",
       "  'question',\n",
       "  'question',\n",
       "  'question',\n",
       "  'question',\n",
       "  'question',\n",
       "  'exclamation',\n",
       "  'statement',\n",
       "  'exclamation',\n",
       "  'question',\n",
       "  'exclamation',\n",
       "  'question',\n",
       "  'statement',\n",
       "  'question',\n",
       "  'exclamation',\n",
       "  'exclamation',\n",
       "  'question',\n",
       "  'statement',\n",
       "  'question',\n",
       "  'statement',\n",
       "  'exclamation',\n",
       "  'statement',\n",
       "  'statement',\n",
       "  'statement',\n",
       "  'question',\n",
       "  'question',\n",
       "  'exclamation',\n",
       "  'exclamation',\n",
       "  'question',\n",
       "  'statement',\n",
       "  'statement',\n",
       "  'exclamation',\n",
       "  'exclamation',\n",
       "  'statement',\n",
       "  'statement',\n",
       "  'question',\n",
       "  'statement',\n",
       "  'statement',\n",
       "  'question',\n",
       "  'question',\n",
       "  'exclamation',\n",
       "  'statement',\n",
       "  'exclamation',\n",
       "  'statement',\n",
       "  'exclamation',\n",
       "  'statement',\n",
       "  'statement',\n",
       "  'statement',\n",
       "  'question',\n",
       "  'exclamation',\n",
       "  'exclamation',\n",
       "  'question',\n",
       "  'exclamation',\n",
       "  'question',\n",
       "  'exclamation',\n",
       "  'exclamation',\n",
       "  'statement',\n",
       "  'statement',\n",
       "  'question',\n",
       "  'question',\n",
       "  'question',\n",
       "  'exclamation',\n",
       "  'question',\n",
       "  'statement',\n",
       "  'statement',\n",
       "  'exclamation',\n",
       "  'exclamation',\n",
       "  'exclamation',\n",
       "  'exclamation',\n",
       "  'exclamation',\n",
       "  'question',\n",
       "  'statement'],\n",
       " ['dudum',\n",
       "  'katkit',\n",
       "  'katkit',\n",
       "  'katkit',\n",
       "  'nul',\n",
       "  'katkit',\n",
       "  'katkit',\n",
       "  'dudum',\n",
       "  'katkit',\n",
       "  'hello',\n",
       "  'hello',\n",
       "  'dudum',\n",
       "  'hello',\n",
       "  'katkit',\n",
       "  'hello',\n",
       "  'katkit',\n",
       "  'katkit',\n",
       "  'katkit',\n",
       "  'nul',\n",
       "  'katkit',\n",
       "  'dudum',\n",
       "  'dudum',\n",
       "  'dudum',\n",
       "  'hello',\n",
       "  'katkit',\n",
       "  'dudum',\n",
       "  'dudum',\n",
       "  'katkit',\n",
       "  'hello',\n",
       "  'dudum',\n",
       "  'hello',\n",
       "  'nul',\n",
       "  'katkit',\n",
       "  'hello',\n",
       "  'katkit',\n",
       "  'hello',\n",
       "  'hello',\n",
       "  'dudum',\n",
       "  'hello',\n",
       "  'hello',\n",
       "  'dudum',\n",
       "  'dudum',\n",
       "  'katkit',\n",
       "  'dudum',\n",
       "  'katkit',\n",
       "  'dudum',\n",
       "  'hello',\n",
       "  'hello',\n",
       "  'katkit',\n",
       "  'nul',\n",
       "  'dudum',\n",
       "  'hello',\n",
       "  'katkit',\n",
       "  'hello',\n",
       "  'nul',\n",
       "  'dudum',\n",
       "  'dudum',\n",
       "  'hello',\n",
       "  'dudum',\n",
       "  'nul',\n",
       "  'hello',\n",
       "  'nul',\n",
       "  'katkit',\n",
       "  'dudum',\n",
       "  'dudum',\n",
       "  'hello',\n",
       "  'katkit',\n",
       "  'katkit',\n",
       "  'dudum',\n",
       "  'dudum',\n",
       "  'katkit',\n",
       "  'katkit',\n",
       "  'katkit',\n",
       "  'dudum',\n",
       "  'hello',\n",
       "  'dudum',\n",
       "  'katkit',\n",
       "  'hello',\n",
       "  'dudum',\n",
       "  'hello',\n",
       "  'hello',\n",
       "  'dudum',\n",
       "  'katkit',\n",
       "  'hello',\n",
       "  'dudum',\n",
       "  'dudum',\n",
       "  'hello',\n",
       "  'nul',\n",
       "  'katkit',\n",
       "  'hello',\n",
       "  'hello',\n",
       "  'hello',\n",
       "  'katkit',\n",
       "  'hello',\n",
       "  'dudum',\n",
       "  'hello',\n",
       "  'nul',\n",
       "  'dudum',\n",
       "  'katkit'])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_pitchnw(grab_file('voice969', 'pitchnw', 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
