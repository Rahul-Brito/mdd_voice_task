{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "cb5680b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/om2/user/rfbrito/miniconda/envs/imaging/lib/python3.11/site-packages/nilearn/glm/first_level/experimental_paradigm.py:89: UserWarning: Unexpected column `nonword` in events data will be ignored.\n",
      "  warnings.warn((\"Unexpected column `{}` in events \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "230405-20:02:17,523 nipype.interface INFO:\n",
      "\t Setting dt = 110 ms\n",
      "\n",
      "230405-20:02:17,525 nipype.interface INFO:\n",
      "\t response sum: 1.0000 max: 0.0231\n",
      "230405-20:02:17,526 nipype.interface INFO:\n",
      "\t reg_scale: 43.1973\n",
      "230405-20:02:17,530 nipype.interface INFO:\n",
      "\t Setting dt = 110 ms\n",
      "\n",
      "230405-20:02:17,531 nipype.interface INFO:\n",
      "\t response sum: 1.0000 max: 0.0231\n",
      "230405-20:02:17,532 nipype.interface INFO:\n",
      "\t reg_scale: 43.1973\n",
      "230405-20:02:17,535 nipype.interface INFO:\n",
      "\t Setting dt = 110 ms\n",
      "\n",
      "230405-20:02:17,537 nipype.interface INFO:\n",
      "\t response sum: 1.0000 max: 0.0231\n",
      "230405-20:02:17,537 nipype.interface INFO:\n",
      "\t reg_scale: 43.1973\n",
      "230405-20:02:17,541 nipype.interface INFO:\n",
      "\t Setting dt = 110 ms\n",
      "\n",
      "230405-20:02:17,542 nipype.interface INFO:\n",
      "\t response sum: 1.0000 max: 0.0231\n",
      "230405-20:02:17,543 nipype.interface INFO:\n",
      "\t reg_scale: 43.1973\n",
      "230405-20:02:17,546 nipype.interface INFO:\n",
      "\t Setting dt = 110 ms\n",
      "\n",
      "230405-20:02:17,547 nipype.interface INFO:\n",
      "\t response sum: 1.0000 max: 0.0231\n",
      "230405-20:02:17,548 nipype.interface INFO:\n",
      "\t reg_scale: 43.1973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/om2/user/rfbrito/miniconda/envs/imaging/lib/python3.11/site-packages/nilearn/glm/first_level/experimental_paradigm.py:89: UserWarning: Unexpected column `nonword` in events data will be ignored.\n",
      "  warnings.warn((\"Unexpected column `{}` in events \"\n"
     ]
    }
   ],
   "source": [
    "#Import packages\n",
    "import os\n",
    "import glob\n",
    "import json\n",
    "#from tqdm import tqdm\n",
    "\n",
    "import nilearn\n",
    "import nibabel as nib\n",
    "from nilearn import image as nimg\n",
    "from nilearn import plotting as nplot\n",
    "from nilearn.glm.first_level import FirstLevelModel, make_first_level_design_matrix, run_glm\n",
    "from nilearn.glm import fdr_threshold,threshold_stats_img\n",
    "from nilearn.glm.contrasts import compute_contrast\n",
    "\n",
    "\n",
    "from bids.layout import BIDSLayout, parse_file_entities\n",
    "\n",
    "# import cortex\n",
    "# from cortex import fmriprep\n",
    "\n",
    "from nipype.interfaces.workbench.base import WBCommand\n",
    "from nipype.algorithms import modelgen\n",
    "from nipype.interfaces.base import Bunch\n",
    "\n",
    "import hcp_utils as hcp\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "#%matplotlib inline\n",
    "#! module load openmind/hcp-workbench/1.2.3\n",
    "\n",
    "def find_populated_events(events_path_pattern):\n",
    "\n",
    "    #get list of all events file in bids directory (using old location) per task as df\n",
    "    #pop_events = pd.DataFrame(glob.glob(f'/om/project/voice/bids/data/sub-voice*/ses-*/func/*{task}*events.tsv'), columns= ['events_file'])\n",
    "\n",
    "    pop_events = pd.DataFrame(glob.glob(events_path_pattern), columns= ['events_file'])\n",
    "\n",
    "    #use pd empty attribute to determine if file is empty or not. \n",
    "    #invert the boolean value as I want to know if it is popualated or not\n",
    "    pop_events['populated'] = [not pd.read_table(f).empty for f in pop_events.events_file]\n",
    "\n",
    "    pop_events['task'] = [parse_file_entities(file)['task'] for file in pop_events.events_file]\n",
    "\n",
    "    return pop_events\n",
    "\n",
    "def create_contrast(design_matrix, task):\n",
    "    #fmri_img = concat_imgs(nifti)\n",
    "    #mean_img = mean_img(fmri_img)\n",
    "    \n",
    "    speech_contrast = np.zeros(design_matrix.shape[1])\n",
    "    \n",
    "    if task == 'pataka':\n",
    "        clear = np.zeros(design_matrix.shape[1])\n",
    "        clear[0] = 1\n",
    "        normal = np.zeros(design_matrix.shape[1])\n",
    "        normal[1] = 1\n",
    "        rapid = np.zeros(design_matrix.shape[1])\n",
    "        rapid[2] = 1\n",
    "        silent = np.zeros(design_matrix.shape[1])\n",
    "        silent[3] = 1\n",
    "\n",
    "\n",
    "        conditions = {\n",
    "            'clear': clear,\n",
    "            'normal': normal,\n",
    "            'rapid': rapid,\n",
    "            'silent': silent\n",
    "        }\n",
    "\n",
    "        speech_contrast = 0.33*conditions['clear'] + 0.33*conditions['normal'] + 0.33*conditions['rapid'] - conditions['silent']\n",
    "    \n",
    "    if task == 'emosent':\n",
    "        happy= np.zeros(design_matrix.shape[1])\n",
    "        happy[0] = 1\n",
    "        neutral= np.zeros(design_matrix.shape[1])\n",
    "        neutral[1] = 1\n",
    "        sad = np.zeros(design_matrix.shape[1])\n",
    "        sad[2] = 1\n",
    "        silent = np.zeros(design_matrix.shape[1])\n",
    "        silent[3] = 1\n",
    "        \n",
    "        conditions = {\n",
    "            'happy': happy,\n",
    "            'neutral': neutral,\n",
    "            'sad': sad,\n",
    "            'silent': silent\n",
    "        }\n",
    "        \n",
    "        speech_contrast = 0.33*conditions['happy'] + 0.33*conditions['neutral'] + 0.33*conditions['sad'] - conditions['silent']\n",
    "    \n",
    "    if task == 'nwr':\n",
    "        two = np.zeros(design_matrix.shape[1])\n",
    "        two[0] = 1\n",
    "        three= np.zeros(design_matrix.shape[1])\n",
    "        three[1] = 1\n",
    "        four = np.zeros(design_matrix.shape[1])\n",
    "        four[2] = 1\n",
    "        five = np.zeros(design_matrix.shape[1])\n",
    "        five[3] = 1\n",
    "        rest = np.zeros(design_matrix.shape[1])\n",
    "        rest[4] = 1\n",
    "        \n",
    "        conditions = {\n",
    "            '2': two,\n",
    "            '3': three,\n",
    "            '4': four,\n",
    "            '5': five,\n",
    "            'Rest' : rest\n",
    "        }\n",
    "        \n",
    "        speech_contrast = 0.25*conditions['2'] + 0.25*conditions['3'] + 0.25*conditions['4'] + 0.25*conditions['5'] - 0.25*conditions['Rest']\n",
    "    \n",
    "    if task == 'vowel':\n",
    "        \n",
    "        high = np.zeros(design_matrix.shape[1])\n",
    "        high[0] = 1\n",
    "        low= np.zeros(design_matrix.shape[1])\n",
    "        low[1] = 1\n",
    "        normal = np.zeros(design_matrix.shape[1])\n",
    "        normal[2] = 1\n",
    "        silent = np.zeros(design_matrix.shape[1])\n",
    "        silent[3] = 1\n",
    "        \n",
    "        conditions = {\n",
    "            'high': high,\n",
    "            'low': low,\n",
    "            'normal': normal,\n",
    "            'silent': silent\n",
    "        }\n",
    "        \n",
    "        speech_contrast = 0.33*conditions['high'] + 0.33*conditions['low'] + 0.33*conditions['normal'] - conditions['silent']\n",
    "    \n",
    "    return speech_contrast\n",
    "\n",
    "def find_low_acompcor(parsed_valid_runs):\n",
    "    low_acompcor_to_drop = []\n",
    "\n",
    "    for pvr in parsed_valid_runs:\n",
    "        sub = pvr['subject']\n",
    "        ses = pvr['session']\n",
    "        run = int(pvr['run'])\n",
    "        task = pvr['task']\n",
    "\n",
    "        all_confounds = pd.read_csv(f\"../../derivatives/fmriprep/sub-{sub}/ses-{ses}/func/sub-{sub}_ses-{ses}_task-{task}_run-{run}_desc-confounds_timeseries.tsv\", sep = '\\t')\n",
    "\n",
    "        all_confounds_json = open(f\"../../derivatives/fmriprep/sub-{sub}/ses-{ses}/func/sub-{sub}_ses-{ses}_task-{task}_run-{run}_desc-confounds_timeseries.json\")\n",
    "        all_confounds_json=json.load(all_confounds_json)\n",
    "\n",
    "        #num_a_comp_cors[f'sub-{sub}_ses-{ses}_task-{task}_run-{run}'] = (len([col for col in all_confounds.columns if 'a_comp_cor' in col]))\n",
    "\n",
    "        if (len([col for col in all_confounds.columns if 'a_comp_cor' in col])) < 5:\n",
    "            low_acompcor_to_drop.append(pvr)\n",
    "            \n",
    "    return low_acompcor_to_drop\n",
    "\n",
    "\n",
    "def get_confounds(sub,task,ses,run):\n",
    "\n",
    "    all_confounds = pd.read_csv(f\"../../derivatives/fmriprep/sub-{sub}/ses-{ses}/func/sub-{sub}_ses-{ses}_task-{task}_run-{run}_desc-confounds_timeseries.tsv\", sep = '\\t')\n",
    "    \n",
    "    all_confounds_json = open(f\"../../derivatives/fmriprep/sub-{sub}/ses-{ses}/func/sub-{sub}_ses-{ses}_task-{task}_run-{run}_desc-confounds_timeseries.json\")\n",
    "    all_confounds_json=json.load(all_confounds_json)\n",
    "    \n",
    "    \n",
    "    #typically included rigid body motion (or those plus squares and derivatives if desired, then must comment out top line and uncomment bottom 3)\n",
    "    motion_params = ['trans_x', 'trans_y', 'trans_z','rot_x','rot_y','rot_z']\n",
    "    #motion_trans_params = [col for col in all_confounds.columns if 'trans' in col] #change to these squares and derivatives if desired\n",
    "    #motion_rot_params = [col for col in all_confounds.columns if 'rot' in col] #change to these if desired\n",
    "    #motion_params=motion_trans_params+motion_rot_params #change to these if desired\n",
    "\n",
    "    \n",
    "    #individual col with single 1 for timepoint of motion\n",
    "    #motion_outliers = [col for col in all_confounds.columns if 'motion_outlier' in col]  \n",
    "    \n",
    "    \n",
    "    #for low freq signal drift\n",
    "    #cannot include this and high-pass temp filter bc already removes low freq fluc\n",
    "    #required if using aCompCor (or tCompCor)\n",
    "    cosine_regressors = [col for col in all_confounds.columns if 'cosine' in col] \n",
    "    \n",
    "    \n",
    "    #these can be adjusted to be from the combined wm csf, for example\n",
    "    #doesn't make sense to use csf and wm signal regression if using these according to fmriprep documentation\n",
    "    #6 is rule of thumb; can pick diff number or specific amount of variance explained\n",
    "    #TO DO clarify if edge/crown regressors are already part of compcor -- unclear in docs and can't find separate regressor in tsv\n",
    "    num_a_comp_cors=5\n",
    "    a_comp_cors = []\n",
    "    for i in range(num_a_comp_cors):\n",
    "        a_comp_cors.append('a_comp_cor_{:02d}'.format(i))\n",
    "    \n",
    "        \n",
    "    #if taking ICA AROMA denoised niftis (~desc-smoothAROMAnonaggr_bold.nii.gz), can't also include ICA noise regressors & MUST drop non-steady state vols\n",
    "    #here we are taking instead the ICA AROMA regressors: aroma_motion_XX\n",
    "#     aroma_regressors_all = [col for col in all_confounds.columns if 'aroma' in col]\n",
    "#     aroma_regressors_noise=[]\n",
    "#     #TO DO: excluding for now, but double check on this!\n",
    "#     for regr in aroma_regressors_all:\n",
    "#         json_name ='aroma_motion_'+str(int(regr.split('aroma_motion_')[1]))\n",
    "#         if all_confounds_json[json_name]['MotionNoise']==True:\n",
    "#             aroma_regressors_noise.append(regr)\n",
    "        \n",
    "\n",
    "    #we need to filter out non-steady state volumes if using cosine regressors, ICA AROMA and CompCor regressors...    \n",
    "    non_steady_state_regressors = [col for col in all_confounds.columns if 'non_steady_state' in col]\n",
    "           \n",
    "    #TO DO: not sure if CSF should be kept since already have aCompCors (excluding for now)\n",
    "    #selected_confounds = all_confounds[['framewise_displacement']+motion_params+motion_outliers+cosine_regressors+a_comp_cors+aroma_regressors_noise+non_steady_state_regressors].copy()\n",
    "\n",
    "    #selected_confounds = all_confounds[['framewise_displacement']+motion_params+cosine_regressors+a_comp_cors+aroma_regressors_noise+non_steady_state_regressors].copy()\n",
    "\n",
    "    selected_confounds = all_confounds[['framewise_displacement']+motion_params+cosine_regressors+a_comp_cors+non_steady_state_regressors].copy()\n",
    "\n",
    "    #selected_confounds = all_confounds[['framewise_displacement']+motion_params].copy()\n",
    "    \n",
    "    #selected_confounds = all_confounds[['framewise_displacement']+motion_params+motion_outliers].copy()\n",
    "\n",
    "    #get rid of nas in first row of derivative and framewise displacement cols\n",
    "    for col in selected_confounds.columns:\n",
    "        if ('derivative' in col) or ('framewise_displacement' in col):\n",
    "            if pd.isna(selected_confounds[col][0]):\n",
    "                selected_confounds[col][0]=0\n",
    "\n",
    "    return selected_confounds\n",
    "\n",
    "def generate_sparse_scan_regressors(nifti, fitted_glm, task_json, events):\n",
    "    \n",
    "    TR=task_json['RepetitionTime']\n",
    "    DT=task_json['DelayTime']\n",
    "\n",
    "    sparse_model = modelgen.SpecifySparseModel()\n",
    "    sparse_model.inputs.input_units = 'secs'\n",
    "    sparse_model.inputs.functional_runs = nifti\n",
    "    sparse_model.inputs.time_repetition = TR\n",
    "    sparse_model.inputs.time_acquisition = TR - DT\n",
    "    sparse_model.inputs.high_pass_filter_cutoff = 128.\n",
    "    sparse_model.inputs.model_hrf = True\n",
    "    sparse_model.inputs.subject_info = modelgen.bids_gen_info(events,condition_column='trial_type')  # doctest: +SKIP\n",
    "\n",
    "    regressors = sparse_model._list_outputs()['session_info'][0]['regress']\n",
    "    data = [v['val'] for v in regressors]\n",
    "    col = [t['name'] for t in regressors]\n",
    "    df_regressors = pd.DataFrame(data).T\n",
    "    df_regressors.columns = col\n",
    "    df_regressors.index = fitted_glm.design_matrices_[0].index\n",
    "    \n",
    "    return df_regressors\n",
    "\n",
    "\n",
    "def convolve_sparse_scan_glm_with_cifti(parsed_valid_runs):\n",
    "    #base directory for fmriprep output\n",
    "    fmriprep_dir = '../../derivatives/fmriprep'\n",
    "\n",
    "    #L-R surface templates\n",
    "    left_surface = '/om2/user/jsmentch/data/datalad/templateflow/tpl-fsLR/tpl-fsLR_hemi-L_den-32k_sphere.surf.gii'\n",
    "    right_surface = '/om2/user/jsmentch/data/datalad/templateflow/tpl-fsLR/tpl-fsLR_hemi-R_den-32k_sphere.surf.gii'\n",
    "\n",
    "    #query list of subjects and runs\n",
    "    # subjects = layout.get_subjects()\n",
    "    # runs = layout.get_runs()\n",
    "\n",
    "    #for PVR in PARSED VALID RUNS of pataka only\n",
    "\n",
    "\n",
    "    sparse = True\n",
    "    space='MNI152NLin6Asym'\n",
    "\n",
    "    sub_level_effect_size = {}\n",
    "\n",
    "    for pvr in parsed_valid_runs:\n",
    "        sub = pvr['subject']\n",
    "        ses = pvr['session']\n",
    "        run = int(pvr['run'])\n",
    "        task = pvr['task']\n",
    "\n",
    "\n",
    "        ###Load CIFTI, smooth, and save\n",
    "\n",
    "        #fmriprep dir for each subject\n",
    "        ses_dir = f'{fmriprep_dir}/sub-{sub}/ses-{ses}'\n",
    "\n",
    "        # add smoothed and cleaned dir to fmriprep for each sub\n",
    "        smoothed_dir = f'{ses_dir}/smoothed'\n",
    "        #cleaned_dir = f'{ses_dir}/cleaned'\n",
    "\n",
    "        #create directories for smoothed and cleaned data\n",
    "        os.makedirs(smoothed_dir, exist_ok=True)\n",
    "        #os.makedirs(cleaned_dir, exist_ok=True)    \n",
    "\n",
    "        #get the cifti file\n",
    "        func_file = glob.glob(f'{fmriprep_dir}/sub-{sub}/ses-{ses}/func/sub-{sub}*ses-{ses}*task-{task}*run-{run}*fsLR_den-91k_bold.dtseries.nii')[0]                      \n",
    "\n",
    "        #smoothing cifti files using connectome workbench\n",
    "        smooth_output_file = f'{smoothed_dir}/{os.path.basename(func_file)}'\n",
    "        wb_command = WBCommand(command='wb_command')\n",
    "        wb_command.inputs.args = f'-cifti-smoothing {func_file} 4 4 COLUMN {smooth_output_file} -right-surface {right_surface} -left-surface {left_surface}'\n",
    "        wb_command.run()\n",
    "\n",
    "        #load smoothed func data\n",
    "        smoothed_func_img = nimg.load_img(smooth_output_file)\n",
    "        smoothed_func_signal = smoothed_func_img.get_fdata()\n",
    "\n",
    "        func_smooth = nib.Cifti2Image(smoothed_func_signal, smoothed_func_img.header)\n",
    "\n",
    "        smooth_output_file = f'{smoothed_dir}/{os.path.basename(func_file)}'\n",
    "        func_smooth.to_filename(smooth_output_file)\n",
    "\n",
    "\n",
    "        ### Get spare resampled timestamps from volumetric data\n",
    "        task_json = open(f\"../../task-{task}_bold.json\")\n",
    "        task_json=json.load(task_json)\n",
    "        TR=task_json['RepetitionTime']\n",
    "\n",
    "        nifti = glob.glob(f'../../derivatives/fmriprep/sub-{sub}/ses-{ses}/func/sub-{sub}*task-{task}*run-{run}*{space}*preproc*nii.gz')[0]\n",
    "        events = glob.glob(f'/nobackup/project/voice/bids/data/sub-{sub}/ses-{ses}/func/sub-{sub}*task-{task}*run-0{run}*events.tsv')\n",
    "\n",
    "        selected_confounds=get_confounds(sub,task,ses,run)\n",
    "\n",
    "        glm = FirstLevelModel(t_r=TR, \n",
    "                              noise_model='ar1',\n",
    "                              drift_model=None,\n",
    "                              standardize=False,\n",
    "                              hrf_model='spm',\n",
    "                              high_pass=None)\n",
    "\n",
    "        fitted_glm = glm.fit(nifti, events=events[0], confounds=selected_confounds)\n",
    "\n",
    "        if sparse:\n",
    "            try:\n",
    "                sparse_scan_regressors = generate_sparse_scan_regressors(nifti, fitted_glm, task_json, events)\n",
    "                fails = None\n",
    "                for event_type in sparse_scan_regressors.columns:\n",
    "                    fitted_glm.design_matrices_[0][event_type] = sparse_scan_regressors[event_type]\n",
    "            except Exception as Arguement:\n",
    "                fails = Arguement\n",
    "\n",
    "        frame_times = fitted_glm.design_matrices_[0].index\n",
    "        design_matrix = make_first_level_design_matrix(frame_times,\n",
    "                                                       events=pd.read_table(events[0]),\n",
    "                                                       drift_model=None,\n",
    "                                                       hrf_model='spm',\n",
    "                                                       high_pass=None\n",
    "                                                       )\n",
    "\n",
    "\n",
    "        selected_confounds.index = design_matrix.index\n",
    "        design_matrix = pd.concat([design_matrix, selected_confounds], axis = 1)\n",
    "        labels, estimates = run_glm(smoothed_func_signal, design_matrix.values)\n",
    "\n",
    "        speech_contrasts = create_contrast(design_matrix, task)\n",
    "        contrast = compute_contrast(labels, estimates, speech_contrasts,\n",
    "                                        contrast_type='t')\n",
    "\n",
    "        sub_level_effect_size[f'sub-{sub}_ses-{ses}_task-{task}_run-{run}'] = contrast.effect_size()\n",
    "\n",
    "    sub_level_effect_size_df = pd.DataFrame(sub_level_effect_size)\n",
    "    return sub_level_effect_size_df\n",
    "\n",
    "events_path_pattern = f'/nobackup/project/voice/bids/data/sub-voice*/ses-*/func/*events.tsv'\n",
    "pop_events = find_populated_events(events_path_pattern)\n",
    "count_pop_events = pop_events.groupby('task').populated.value_counts()\n",
    "\n",
    "valid_runs = pop_events.events_file[pop_events.populated == True]\n",
    "parsed_valid_runs = [parse_file_entities(vr) for vr in valid_runs]\n",
    "\n",
    "subjects_excluded = ['voice997', 'voice897','voice863'] #for some reason these one is not in the fmriprep output\n",
    "parsed_valid_runs = [pvr for pvr in parsed_valid_runs if pvr['subject'] not in subjects_excluded]\n",
    "\n",
    "low_acompcor_to_drop = find_low_acompcor(parsed_valid_runs)\n",
    "parsed_valid_runs = [r for r in parsed_valid_runs if r not in low_acompcor_to_drop]\n",
    "\n",
    "parsed_valid_runs = parsed_valid_runs[5:6]\n",
    "\n",
    "sub_level_effect_size_df = convolve_sparse_scan_glm_with_cifti(parsed_valid_runs)\n",
    "#sub_level_effect_size_df.to_pickle('sub_level_effect_size_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713aa280",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
